episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,24,-0.006996381329685369,-0.010719071806273147,-0.625,0.0,0.0,-0.005000000000000002,0.15473533193606048,-0.16791315191244885,-0.2572577233505555,-15.0,0.0,0.0,-0.12000000000000004,3.7136479664654516,1,False,True,False,1764700202.0573077
2,186,-0.005370006959335801,-0.003176834839309428,0.0,0.0,-0.010752688172043012,-0.005000000000000004,0.05472159156029819,-0.998821294436459,-0.5908912801115536,0.0,0.0,-2.0,-0.9300000000000007,10.178216030215463,0,False,False,True,1764700237.257775
3,400,-0.005343776611174926,-0.0013684320021893396,0.0,0.0,0.0,-0.004999999999999948,0.20260230728867687,-2.1375106444699705,-0.5473728008757358,0.0,0.0,0.0,-1.9999999999999793,81.04092291547074,0,False,False,True,1764700291.4923785
