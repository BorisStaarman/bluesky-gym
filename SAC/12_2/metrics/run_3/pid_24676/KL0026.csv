episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,6,-0.0010985224327691237,0.010868576208241906,-2.5,0.0,0.0,-0.005,0.32227891933072605,-0.006591134596614742,0.06521145724945143,-15.0,0.0,0.0,-0.030000000000000002,1.9336735159843563,1,False,True,False,1764700200.4755368
2,54,-0.0010584330897719647,0.014893719383489904,0.0,0.0,0.0,-0.005000000000000003,0.43600342768244793,-0.05715538684768609,0.8042608467084549,0.0,0.0,0.0,-0.27000000000000013,23.54418509485219,0,False,True,False,1764700227.3791926
3,400,-0.004942125812320676,0.0014324082352404127,0.0,0.0,0.0,-0.004999999999999948,0.004228665874385033,-1.9768503249282705,0.5729632940961651,0.0,0.0,0.0,-1.9999999999999793,1.691466349754013,0,False,False,True,1764700291.4923785
