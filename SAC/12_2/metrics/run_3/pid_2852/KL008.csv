episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,98,-0.0025994104499430146,0.007897941615756621,0.0,0.0,-0.02040816326530612,-0.005000000000000004,0.3061178173285571,-0.25474222409441544,0.7739982783441489,0.0,0.0,-2.0,-0.4900000000000003,29.999546098198596,0,False,False,True,1764700206.1056678
2,91,-0.003137228401795818,0.0076298597742183545,-1.6483516483516483,0.0,-0.02197802197802198,-0.005000000000000004,0.2034450155042756,-0.28548778456341944,0.6943172394538702,-150.0,0.0,-2.0,-0.4550000000000003,18.51349641088908,10,False,False,True,1764700214.7709658
