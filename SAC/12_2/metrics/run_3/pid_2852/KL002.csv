episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,33,-0.004192199815735785,0.0014745705995188015,-0.45454545454545453,0.0,0.0,-0.005000000000000002,0.07284563640374217,-0.13834259391928092,0.04866082978412045,-15.0,0.0,0.0,-0.16500000000000006,2.4039060013234916,1,False,True,False,1764700202.8003473
2,83,-0.006832870817981839,-0.010819176268767399,0.0,0.0,-0.024096385542168676,-0.005000000000000003,0.20976358132694267,-0.5671282778924926,-0.8979916303076941,0.0,0.0,-2.0,-0.41500000000000026,17.410377250136243,0,False,False,True,1764700214.1137028
3,144,-0.0058873274501913785,-0.0064540451730658545,-0.3125,0.0,-0.013888888888888888,-0.005000000000000004,0.10608098059826841,-0.8477751528275586,-0.929382504921483,-45.0,0.0,-2.0,-0.7200000000000005,15.275661206150652,3,False,False,True,1764700223.981686
