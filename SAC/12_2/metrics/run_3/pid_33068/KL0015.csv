episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,280,-0.004759919389762571,-0.000296970922628041,0.0,0.0,-0.007142857142857143,-0.004999999999999972,0.18734861665125413,-1.33277742913352,-0.08315185833585148,0.0,0.0,-2.0,-1.3999999999999921,52.45761266235116,0,False,False,True,1764700218.0432417
