episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,30,-0.0056214681968330266,-0.0045968541011868,0.0,0.0,-0.06666666666666667,-0.005000000000000002,0.03326595627213766,-0.1686440459049908,-0.137905623035604,0.0,0.0,-2.0,-0.15000000000000005,0.9979786881641297,0,False,False,True,1764700202.5831463
2,204,-0.00504695752383568,-0.0014677601609481283,0.0,0.0,-0.00980392156862745,-0.005000000000000001,0.03735402819454104,-1.0295793348624787,-0.2994230728334182,0.0,0.0,-2.0,-1.0200000000000002,7.620221751686372,0,False,False,True,1764700230.5788386
