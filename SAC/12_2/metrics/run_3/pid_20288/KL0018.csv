episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,19,-0.004030388674877385,0.0010916543342381084,0.0,0.0,0.0,-0.005000000000000001,0.07850530945056121,-0.07657738482267032,0.02074143235052406,0.0,0.0,0.0,-0.09500000000000001,1.491600879560663,0,False,True,False,1764700201.6326632
2,226,-0.0038250824986625085,0.004279416439202586,0.0,0.0,-0.008849557522123894,-0.0049999999999999906,0.18272691682372444,-0.8644686446977269,0.9671481152597845,0.0,0.0,-2.0,-1.129999999999998,41.296283202161725,0,False,False,True,1764700226.5290964
