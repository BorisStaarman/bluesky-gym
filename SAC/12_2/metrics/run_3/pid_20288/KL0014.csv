episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,101,-0.005804529171374961,-0.004503923766538117,-0.44554455445544555,0.0,-0.019801980198019802,-0.005000000000000004,0.26381495765115986,-0.5862574463088711,-0.4548963004203498,-45.0,0.0,-2.0,-0.5050000000000003,26.645310722767146,3,False,False,True,1764700206.2761986
2,5,-0.002915271117256312,0.004182856727695761,-3.0,0.0,0.0,-0.005,0.43698336762837026,-0.01457635558628156,0.020914283638478803,-15.0,0.0,0.0,-0.025,2.1849168381418513,1,False,True,False,1764700212.660587
3,400,-0.004935234550712253,-0.00046721005512576465,-0.225,0.0,0.0,-0.004999999999999948,0.05349394392321482,-1.974093820284901,-0.18688402205030585,-90.0,0.0,0.0,-1.9999999999999793,21.39757756928593,6,False,False,True,1764700271.2876067
