episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,3,-0.0023576752839712207,0.006278982474861472,-5.0,0.0,0.0,-0.005,0.6088243559711595,-0.007073025851913662,0.018836947424584416,-15.0,0.0,0.0,-0.015,1.8264730679134784,1,False,True,False,1764700200.1489048
2,122,-0.003601209233563842,0.00284567729490861,-1.3524590163934427,0.0,-0.01639344262295082,-0.005000000000000004,0.4942425318784664,-0.43934752649478875,0.34717262997885046,-165.0,0.0,-2.0,-0.6100000000000004,60.2975888891729,11,False,False,True,1764700220.6868672
3,400,-0.005079444715225979,-0.0012900639537504457,0.0,0.0,0.0,-0.004999999999999948,0.00714556365461547,-2.0317778860903917,-0.5160255815001783,0.0,0.0,0.0,-1.9999999999999793,2.858225461846188,0,False,False,True,1764700271.2876067
