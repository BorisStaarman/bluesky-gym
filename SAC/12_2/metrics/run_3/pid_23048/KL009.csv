episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,6,-0.0027218023668452687,0.005772435904013514,-2.5,0.0,0.0,-0.005,0.5175915044893044,-0.016330814201071613,0.03463461542408108,-15.0,0.0,0.0,-0.030000000000000002,3.105549026935826,1,False,True,False,1764700200.4925907
2,36,-0.002721656880260428,0.008015199586841666,-0.4166666666666667,0.0,0.0,-0.005000000000000002,0.04571550274524813,-0.09797964768937542,0.28854718512629995,-15.0,0.0,0.0,-0.18000000000000008,1.6457580988289329,1,False,True,False,1764700221.6577473
3,400,-0.004950908025677136,-0.0004610826174398408,0.0,0.0,0.0,-0.004999999999999948,0.25427809183675093,-1.9803632102708544,-0.18443304697593632,0.0,0.0,0.0,-1.9999999999999793,101.71123673470036,0,False,False,True,1764700283.294657
