episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,296,-0.004866012179769475,-0.0007834923610917959,0.0,0.0,-0.006756756756756757,-0.004999999999999968,0.16135085661895013,-1.4403396052117645,-0.23191373888317157,0.0,0.0,-2.0,-1.4799999999999904,47.75985355920924,0,False,False,True,1764700219.3594322
2,212,-0.005822697571711573,-0.005732270336097489,0.0,0.0,-0.009433962264150943,-0.0049999999999999975,0.10688459864344227,-1.2344118852028534,-1.2152413112526677,0.0,0.0,-2.0,-1.0599999999999994,22.65953491240976,0,False,False,True,1764700231.861565
