episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,37,-0.003839005139596385,0.05753997436889825,0.0,0.0,0.0,-0.005000000000000002,0.0,-0.14204319016506625,2.1289790516492353,0.0,0.0,0.0,-0.18500000000000008,0.0,0,True,False,False,1764700203.0262318
2,5,-0.001859362777219408,0.008749564953702849,-3.0,0.0,0.0,-0.005,0.33639822539561026,-0.00929681388609704,0.04374782476851424,-15.0,0.0,0.0,-0.025,1.6819911269780514,1,False,True,False,1764700220.935554
3,292,-0.005650936569947331,-0.0028462470953305465,-3.2363013698630136,0.0,-0.00684931506849315,-0.004999999999999969,0.3559667836840433,-1.6500734784246207,-0.8311041518365195,-945.0,0.0,-2.0,-1.4599999999999909,103.94230083574064,63,False,False,True,1764700284.249377
