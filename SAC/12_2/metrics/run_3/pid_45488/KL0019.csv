episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,80,-0.006114347103620239,-0.00626572473484488,-4.3125,0.0,-0.025,-0.005000000000000003,0.4817728901433071,-0.48914776828961914,-0.5012579787875904,-345.0,0.0,-2.0,-0.40000000000000024,38.54183121146457,23,False,False,True,1764700205.220532
2,309,-0.004894109743029026,-0.0001361166851178706,0.0,0.0,-0.006472491909385114,-0.0049999999999999645,0.049674777737116496,-1.512279910595969,-0.04206005570142202,0.0,0.0,-2.0,-1.544999999999989,15.349506320768997,0,False,False,True,1764700245.4709706
