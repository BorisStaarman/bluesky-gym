episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,38,-0.002809987218335613,0.004813935454354428,-7.105263157894737,0.0,0.0,-0.005000000000000002,0.6347265875848437,-0.1067795142967533,0.18292954726546828,-270.0,0.0,0.0,-0.19000000000000009,24.11961032822406,18,False,True,False,1764700203.123299
2,49,-0.0017789996995334605,0.01026950372487206,-0.30612244897959184,0.0,0.0,-0.005000000000000003,0.0998947732456175,-0.08717098527713957,0.5032056825187309,-15.0,0.0,0.0,-0.24500000000000013,4.894843889035258,1,False,True,False,1764700210.305356
3,161,-0.006436498223081248,-0.006704993360788096,0.0,0.0,-0.012422360248447204,-0.005000000000000004,0.3641431295231308,-1.0362762139160808,-1.0795039310868835,0.0,0.0,-2.0,-0.8050000000000006,58.62704385322406,0,False,False,True,1764700224.231608
