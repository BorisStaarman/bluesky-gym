episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,8,-0.0011281189739836734,0.01014381139061988,-1.875,0.0,0.0,-0.005,0.19708637028488163,-0.009024951791869388,0.08115049112495903,-15.0,0.0,0.0,-0.04,1.576690962279053,1,False,True,False,1764700200.7357397
2,102,-0.006057215605561019,-0.00623194579751178,0.0,0.0,-0.0196078431372549,-0.005000000000000004,0.14585187671103006,-0.6178359917672239,-0.6356584713462016,0.0,0.0,-2.0,-0.5100000000000003,14.876891424525066,0,False,False,True,1764700213.7439969
