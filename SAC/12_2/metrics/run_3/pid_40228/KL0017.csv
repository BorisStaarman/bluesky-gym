episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,359,-0.0049836940440675945,-0.002104089912072351,-0.6267409470752089,0.0,-0.005571030640668524,-0.004999999999999955,0.09381266485701409,-1.7891461618202664,-0.7553682784339741,-225.0,0.0,-2.0,-1.7949999999999837,33.67874668366806,15,False,False,True,1764700222.9432454
