episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,22,-0.0015245128489190449,0.01032758881795708,-0.6818181818181818,0.0,0.0,-0.005000000000000001,0.0662967274169919,-0.03353928267621899,0.22720695399505575,-15.0,0.0,0.0,-0.11000000000000003,1.458528003173822,1,False,True,False,1764700201.8643823
2,49,-0.003603247926994292,0.0022981193840006416,0.0,0.0,0.0,-0.005000000000000003,0.2615063599396869,-0.1765591484227203,0.11260784981603145,0.0,0.0,0.0,-0.24500000000000013,12.813811637044658,0,False,True,False,1764700225.8546283
3,400,-0.0047692288952005035,0.0015617294684301516,0.0,0.0,0.0,-0.004999999999999948,0.05028498602734532,-1.9076915580802014,0.6246917873720607,0.0,0.0,0.0,-1.9999999999999793,20.113994410938126,0,False,False,True,1764700288.8954592
