episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,11,-0.004591334339483242,-0.00044574599013624816,0.0,0.0,-0.18181818181818182,-0.004999999999999999,0.0,-0.05050467773431566,-0.00490320589149873,0.0,0.0,-2.0,-0.05499999999999999,0.0,0,False,False,True,1764700201.0350828
2,186,-0.00458174418588466,-9.96044317688517e-05,0.0,0.0,-0.010752688172043012,-0.005000000000000004,0.018103053667275708,-0.8522044185745467,-0.018526424309006417,0.0,0.0,-2.0,-0.9300000000000007,3.3671679821132816,0,False,False,True,1764700235.254907
