episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,66,-0.0013465202932977174,0.04553785658547241,0.0,0.0,0.0,-0.005000000000000003,0.13013687870856563,-0.08887033935764935,3.005498534641179,0.0,0.0,0.0,-0.3300000000000002,8.589033994765332,0,True,False,False,1764700204.5805833
2,197,-0.005688230923933092,-0.00496389898093848,0.0,0.0,-0.01015228426395939,-0.005000000000000004,0.0794779480659862,-1.1205814920148192,-0.9778880992448806,0.0,0.0,-2.0,-0.9850000000000008,15.65715576899928,0,False,False,True,1764700220.2536113
