episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,3,-0.0008330164511237238,0.011942109009283497,-5.0,0.0,0.0,-0.005,0.7933034106708822,-0.0024990493533711714,0.03582632702785049,-15.0,0.0,0.0,-0.015,2.3799102320126466,1,False,True,False,1764700200.0967393
2,8,-0.003993566012316864,0.002147228577257271,-1.875,0.0,0.0,-0.005,0.41621366920813824,-0.03194852809853491,0.017177828618058166,-15.0,0.0,0.0,-0.04,3.329709353665106,1,False,True,False,1764700207.590442
3,127,-0.003823588044691559,0.00321666702467,0.0,0.0,-0.015748031496062992,-0.005000000000000004,0.47194244257385354,-0.485595681675828,0.40851671213309,0.0,0.0,-2.0,-0.6350000000000005,59.9366902068794,0,False,False,True,1764700228.046055
