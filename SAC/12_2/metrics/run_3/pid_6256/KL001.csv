episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,262,-0.004122427977014029,0.002999391144967426,0.0,0.0,-0.007633587786259542,-0.0049999999999999776,0.04470338161398713,-1.0800761299776758,0.7858404799814657,0.0,0.0,-2.0,-1.309999999999994,11.712285982864628,0,False,False,True,1764700216.9316592
