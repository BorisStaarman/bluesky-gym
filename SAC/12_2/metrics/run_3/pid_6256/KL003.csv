episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,47,-0.0029408913717626304,0.004123371175492808,0.0,0.0,0.0,-0.005000000000000003,0.034863195229840126,-0.13822189447284364,0.19379844524816198,0.0,0.0,0.0,-0.23500000000000013,1.6385701758024858,0,False,True,False,1764700203.6583295
2,174,-0.0031802135894259164,0.018248912948114853,0.0,0.0,0.0,-0.005000000000000004,0.14321438430407823,-0.5533571645601094,3.1753108529719842,0.0,0.0,0.0,-0.8700000000000007,24.91930286890961,0,True,False,False,1764700227.6712098
