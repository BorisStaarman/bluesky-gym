episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,41,-0.005839019339401851,-0.00702089317934175,0.0,0.0,-0.04878048780487805,-0.005000000000000003,0.0,-0.23939979291547592,-0.28785662035301174,0.0,0.0,-2.0,-0.2050000000000001,0.0,0,False,False,True,1764700203.3137586
2,128,-0.0031417663152466216,0.006484182553608742,-0.8203125,0.0,-0.015625,-0.005000000000000004,0.3439827724626273,-0.40214608835156757,0.829975366861919,-105.0,0.0,-2.0,-0.6400000000000005,44.0297948752163,7,False,False,True,1764700216.2122297
3,157,-0.004629978822948395,0.00029652960749091507,-0.28662420382165604,0.0,-0.012738853503184714,-0.005000000000000004,0.31544844589127163,-0.726906675202898,0.04655514837607366,-45.0,0.0,-2.0,-0.7850000000000006,49.52540600492965,3,False,False,True,1764700225.9684741
