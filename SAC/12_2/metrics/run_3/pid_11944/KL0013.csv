episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,10,-0.0032802495675490323,0.004665329698198351,-1.5,0.0,0.0,-0.004999999999999999,0.18707056157738755,-0.032802495675490324,0.046653296981983505,-15.0,0.0,0.0,-0.049999999999999996,1.8707056157738755,1,False,True,False,1764700200.8881779
2,155,-0.0054350039553987565,-0.0036525470355168086,0.0,0.0,-0.012903225806451613,-0.005000000000000004,0.006632382080820569,-0.8424256130868073,-0.5661447905051054,0.0,0.0,-2.0,-0.7750000000000006,1.0280192225271882,0,False,False,True,1764700223.1577914
