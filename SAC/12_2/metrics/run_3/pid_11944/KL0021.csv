episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,208,-0.0033741647707858607,0.00380915091610951,0.0,0.0,-0.009615384615384616,-0.004999999999999999,0.13422731900749713,-0.7018262723234591,0.7923033905507781,0.0,0.0,-2.0,-1.0399999999999998,27.919282353559403,0,False,False,True,1764700212.9828787
