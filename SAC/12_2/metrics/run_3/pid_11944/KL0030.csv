episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,8,-0.001528750320952827,0.00922618219032445,-1.875,0.0,0.0,-0.005,0.23992561171287502,-0.012230002567622616,0.0738094575225956,-15.0,0.0,0.0,-0.04,1.9194048937030002,1,False,True,False,1764700200.7504606
2,4,-0.0005987888362049658,0.012551750731467276,-3.75,0.0,0.0,-0.005,0.6912977599214263,-0.002395155344819863,0.050207002925869104,-15.0,0.0,0.0,-0.02,2.765191039685705,1,False,True,False,1764700213.4273927
3,400,-0.004595156306310188,0.0008369293117977422,0.0,0.0,0.0,-0.004999999999999948,0.028086556603788407,-1.838062522524075,0.3347717247190969,0.0,0.0,0.0,-1.9999999999999793,11.234622641515363,0,False,False,True,1764700263.5117772
