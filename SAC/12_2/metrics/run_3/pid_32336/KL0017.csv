episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,10,-0.0007156366022612476,0.01585906985905381,0.0,0.0,0.0,-0.004999999999999999,0.14788759805370336,-0.007156366022612475,0.1585906985905381,0.0,0.0,0.0,-0.049999999999999996,1.4788759805370335,0,False,True,False,1764700200.88718
2,83,-0.002842899928989691,0.009102729494067045,-0.9036144578313253,0.0,-0.024096385542168676,-0.005000000000000003,0.3948868213697855,-0.23596069410614437,0.7555265480075647,-75.0,0.0,-2.0,-0.41500000000000026,32.775606173692196,5,False,False,True,1764700216.405033
3,280,-0.005360857275222233,-0.0023567170877843045,-0.05357142857142857,0.0,-0.007142857142857143,-0.004999999999999972,0.15397008754163458,-1.5010400370622252,-0.6598807845796053,-15.0,0.0,-2.0,-1.3999999999999921,43.11162451165768,1,False,False,True,1764700237.2308664
