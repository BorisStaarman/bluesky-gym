episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,12,-0.0022764961765734636,0.01107106513345188,-1.25,0.0,0.0,-0.004999999999999999,0.2131491470334638,-0.027317954118881563,0.13285278160142255,-15.0,0.0,0.0,-0.05999999999999999,2.5577897644015657,1,False,True,False,1764700201.0966308
2,109,-0.006636494355935203,-0.00943139597367189,-0.6880733944954128,0.0,-0.01834862385321101,-0.005000000000000004,0.3703179387035225,-0.7233778847969371,-1.028022161130236,-75.0,0.0,-2.0,-0.5450000000000004,40.36465531868395,5,False,False,True,1764700218.168294
