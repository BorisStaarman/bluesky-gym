episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,223,-0.005216006781043864,-0.0032131964352621,0.0,0.0,-0.008968609865470852,-0.004999999999999992,0.07550196282280598,-1.1631695121727816,-0.7165428050634483,0.0,0.0,-2.0,-1.1149999999999982,16.836937709485735,0,False,False,True,1764700213.946784
