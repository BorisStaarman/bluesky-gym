episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,9,-0.0027424197459341593,0.006886125025033052,0.0,0.0,0.0,-0.005,0.3790343152018378,-0.024681777713407436,0.06197512522529747,0.0,0.0,0.0,-0.045,3.41130883681654,0,False,True,False,1764700200.7988245
2,246,-0.0040788135046260655,0.001628165796470453,-0.4878048780487805,0.0,-0.008130081300813009,-0.004999999999999983,0.20704576334283786,-1.003388122138012,0.4005287859317314,-120.0,0.0,-2.0,-1.2299999999999958,50.93325778233812,8,False,False,True,1764700229.7092104
