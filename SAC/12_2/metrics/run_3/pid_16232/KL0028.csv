episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,66,-0.004252500398796098,0.0008614466170726435,0.0,0.0,-0.030303030303030304,-0.005000000000000003,0.0,-0.28066502632054247,0.056855476726794474,0.0,0.0,-2.0,-0.3300000000000002,0.0,0,False,False,True,1764700204.6278303
2,2,-0.0014188571240956625,0.01010817225831201,0.0,0.0,-1.0,-0.005,0.0,-0.002837714248191325,0.02021634451662402,0.0,0.0,-2.0,-0.01,0.0,0,False,False,True,1764700214.266671
3,380,-0.005527926527940756,-0.0021443483220735327,0.0,0.0,-0.005263157894736842,-0.0049999999999999515,0.0904114312327672,-2.1006120806174873,-0.8148523623879423,0.0,0.0,-2.0,-1.8999999999999815,34.35634386845153,0,False,False,True,1764700275.0067425
