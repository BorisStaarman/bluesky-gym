episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,71,-0.004028137805221785,0.0014343109260264524,-0.2112676056338028,0.0,0.0,-0.005000000000000003,0.37892094231353973,-0.2859977841707467,0.10183607574787812,-15.0,0.0,0.0,-0.3550000000000002,26.90338690426132,1,False,True,False,1764700204.835726
2,202,-0.005088088488183745,-0.0017584648208009066,0.0,0.0,-0.009900990099009901,-0.005000000000000002,0.08099637034316508,-1.0277938746131166,-0.35520989380178314,0.0,0.0,-2.0,-1.0100000000000005,16.361266809319346,0,False,False,True,1764700228.2588363
