episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,8,-0.0024985310277558293,0.005637125699438229,0.0,0.0,0.0,-0.005,0.3821386518980571,-0.019988248222046635,0.045097005595505835,0.0,0.0,0.0,-0.04,3.057109215184457,0,False,True,False,1764700200.7397382
2,17,-0.007228826220824319,-0.0026720687515905525,-0.8823529411764706,0.0,0.0,-0.005,0.16646132996874152,-0.12289004575401342,-0.04542516877703939,-15.0,0.0,0.0,-0.085,2.829842609468606,1,False,True,False,1764700216.7965846
3,175,-0.003983948628657386,0.0025173478899600927,0.0,0.0,-0.011428571428571429,-0.005000000000000004,0.006968879029020857,-0.6971910100150426,0.4405358807430162,0.0,0.0,-2.0,-0.8750000000000007,1.21955383007865,0,False,False,True,1764700244.6866822
