episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,44,-0.004949534322172277,-0.00047033960171225723,-2.727272727272727,0.0,0.0,-0.005000000000000003,0.2987986317700825,-0.2177795101755802,-0.020694942475339317,-120.0,0.0,0.0,-0.2200000000000001,13.147139797883629,8,False,True,False,1764700203.50894
2,122,-0.0032603080688603033,0.006062006701426023,-0.36885245901639346,0.0,-0.01639344262295082,-0.005000000000000004,0.5218707827264448,-0.397757584400957,0.7395648175739749,-45.0,0.0,-2.0,-0.6100000000000004,63.668235492626266,3,False,False,True,1764700220.231345
