episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,10,-0.005549349553369058,-0.0009798962908384556,-1.5,0.0,0.0,-0.004999999999999999,0.16657836323736294,-0.05549349553369058,-0.009798962908384556,-15.0,0.0,0.0,-0.049999999999999996,1.6657836323736295,1,False,True,False,1764700200.8775423
2,9,-0.003171501819730207,0.004975524498757069,0.0,0.0,0.0,-0.005,0.6946520805999333,-0.028543516377571864,0.044779720488813624,0.0,0.0,0.0,-0.045,6.2518687253994,0,False,True,False,1764700212.509302
3,218,-0.004822816157431846,0.0002500279409709416,-0.41284403669724773,0.0,-0.009174311926605505,-0.004999999999999994,0.054353800143882684,-1.0513739223201424,0.05450609113166527,-90.0,0.0,-2.0,-1.0899999999999987,11.849128431366426,6,False,False,True,1764700233.0224097
