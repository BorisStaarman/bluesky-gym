episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,31,-0.005511211868986367,-0.005041328100142204,-0.4838709677419355,0.0,0.0,-0.005000000000000002,0.08291318171278238,-0.17084756793857736,-0.1562811711044083,-15.0,0.0,0.0,-0.15500000000000005,2.570308633096254,1,False,True,False,1764700202.631158
2,172,-0.0025410034962978748,0.009414176762852874,0.0,0.0,-0.011627906976744186,-0.005000000000000004,0.0988945063243421,-0.4370526013632344,1.6192384032106943,0.0,0.0,-2.0,-0.8600000000000007,17.009855087786843,0,False,False,True,1764700220.7058976
