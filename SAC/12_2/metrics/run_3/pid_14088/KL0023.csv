episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,64,-0.0050160291912936346,-0.0037458669325543294,0.0,0.0,-0.03125,-0.005000000000000003,0.09765927018593042,-0.3210258682427926,-0.23973548368347708,0.0,0.0,-2.0,-0.3200000000000002,6.250193291899547,0,False,False,True,1764700204.447357
2,19,-0.0008124772809147275,0.11879504167703282,-2.3684210526315788,0.0,0.0,-0.005000000000000001,0.33682677476976375,-0.015437068337379822,2.2571057918636237,-45.0,0.0,0.0,-0.09500000000000001,6.399708720625511,3,True,False,False,1764700210.3225968
3,130,-0.0050262611689183565,-0.0017927246679118884,-0.11538461538461539,0.0,-0.015384615384615385,-0.005000000000000004,0.2084403330447516,-0.6534139519593863,-0.2330542068285455,-15.0,0.0,-2.0,-0.6500000000000005,27.09724329581771,1,False,False,True,1764700228.6130133
