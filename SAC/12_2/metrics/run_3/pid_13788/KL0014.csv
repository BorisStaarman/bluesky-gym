episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,29,-0.003920453133901305,0.002856286527578943,0.0,0.0,-0.06896551724137931,-0.005000000000000002,0.1382188992023456,-0.11369314088313784,0.08283230929978935,0.0,0.0,-2.0,-0.14500000000000005,4.008348076868022,0,False,False,True,1764700202.5539584
2,15,-0.0012998834969887613,0.00974958894772658,-1.0,0.0,0.0,-0.005,0.14281370534890325,-0.01949825245483142,0.1462438342158987,-15.0,0.0,0.0,-0.075,2.142205580233549,1,False,True,False,1764700207.0086865
3,195,-0.004923059064067739,-0.0012276834016887448,-0.5384615384615384,0.0,-0.010256410256410256,-0.005000000000000004,0.040768099120735736,-0.9599965174932092,-0.23939826332930525,-105.0,0.0,-2.0,-0.9750000000000008,7.949779328543468,7,False,False,True,1764700236.037633
