episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,9,-0.002975864763815384,0.0039599450370792055,0.0,0.0,0.0,-0.005,0.385096018102868,-0.026782782874338457,0.03563950533371285,0.0,0.0,0.0,-0.045,3.465864162925812,0,False,True,False,1764700200.778995
2,257,-0.0038242325558720033,0.0035308434436243743,0.0,0.0,-0.007782101167315175,-0.004999999999999979,0.1676355611700479,-0.9828277668591049,0.9074267650114642,0.0,0.0,-2.0,-1.2849999999999946,43.08233922070231,0,False,False,True,1764700222.7357585
