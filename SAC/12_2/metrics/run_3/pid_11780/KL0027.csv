episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,5,-0.002503036467410808,0.006554072336172945,-3.0,0.0,0.0,-0.005,0.5347561078814986,-0.01251518233705404,0.032770361680864724,-15.0,0.0,0.0,-0.025,2.673780539407493,1,False,True,False,1764700200.3963227
2,240,-0.004793471420108964,-0.0004412908281350242,0.0,0.0,-0.008333333333333333,-0.004999999999999985,0.10232596883768466,-1.1504331408261512,-0.1059097987524058,0.0,0.0,-2.0,-1.1999999999999964,24.558232521044317,0,False,False,True,1764700224.6336138
