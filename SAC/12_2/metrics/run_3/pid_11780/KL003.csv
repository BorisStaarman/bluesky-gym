episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,6,-0.0024375370637528073,0.007470023231921215,0.0,0.0,-0.3333333333333333,-0.005,0.0,-0.014625222382516843,0.04482013939152729,0.0,0.0,-2.0,-0.030000000000000002,0.0,0,False,False,True,1764700200.4675353
2,26,-0.004590664810644244,0.0010951452739463936,-4.615384615384615,0.0,0.0,-0.005000000000000001,0.3662026676150569,-0.11935728507675034,0.028473777122606236,-120.0,0.0,0.0,-0.13000000000000003,9.521269357991478,8,False,True,False,1764700210.7730105
3,184,-0.004805551166106371,-0.001891502179675661,0.0,0.0,-0.010869565217391304,-0.005000000000000004,0.045845104047142614,-0.8842214145635722,-0.34803640106032163,0.0,0.0,-2.0,-0.9200000000000007,8.43549914467424,0,False,False,True,1764700238.4485068
