episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,10,-0.001324071298532202,0.20870240762686523,0.0,0.0,0.0,-0.004999999999999999,0.029771472620288415,-0.01324071298532202,2.0870240762686523,0.0,0.0,0.0,-0.049999999999999996,0.29771472620288414,0,True,False,False,1764586778.0313199
2,4,-0.0036701801142660427,0.0029351201536057248,0.0,0.0,0.0,-0.005,0.5340606878050538,-0.01468072045706417,0.011740480614422899,0.0,0.0,0.0,-0.02,2.136242751220215,0,False,True,False,1764586785.2965617
3,148,-0.004329898442085849,-0.0004209613342614103,-0.40540540540540543,0.0,-0.013513513513513514,-0.005000000000000004,0.1896091619225031,-0.6408249694287057,-0.06230227747068873,-60.0,0.0,-2.0,-0.7400000000000005,28.062155964530458,4,False,False,True,1764586799.2855268
