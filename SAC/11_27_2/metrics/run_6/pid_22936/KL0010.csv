episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,6,-0.000552915925879418,0.009465712104978227,-2.5,0.0,0.0,-0.005,0.3555412862477115,-0.003317495555276508,0.05679427262986936,-15.0,0.0,0.0,-0.030000000000000002,2.133247717486269,1,False,True,False,1764586777.7955256
2,109,-0.0036674006441862876,0.002736901109267398,0.0,0.0,-0.01834862385321101,-0.005000000000000004,0.07156781981211571,-0.39974667021630533,0.2983222209101464,0.0,0.0,-2.0,-0.5450000000000004,7.800892359520613,0,False,False,True,1764586791.8314478
