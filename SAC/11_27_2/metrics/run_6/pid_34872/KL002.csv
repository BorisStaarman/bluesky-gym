episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,54,-0.006357879253476342,-0.008997776413036871,0.0,0.0,-0.037037037037037035,-0.005000000000000003,0.06083443968125498,-0.3433254796877225,-0.485879926303991,0.0,0.0,-2.0,-0.27000000000000013,3.285059742787769,0,False,False,True,1764586780.0628486
2,149,-0.006533925175852382,-0.008121249768326842,0.0,0.0,-0.013422818791946308,-0.005000000000000004,0.08731683374981164,-0.9735548512020049,-1.2100662154806994,0.0,0.0,-2.0,-0.7450000000000006,13.010208228721934,0,False,False,True,1764586792.237862
