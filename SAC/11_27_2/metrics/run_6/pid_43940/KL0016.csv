episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,27,-0.0021009745277106645,0.008051950541278493,-0.5555555555555556,0.0,0.0,-0.005000000000000001,0.09007433777844139,-0.05672631224818794,0.2174026646145193,-15.0,0.0,0.0,-0.13500000000000004,2.4320071200179174,1,False,True,False,1764586778.917162
2,28,-0.0034803814626448494,0.0026849565437704137,0.0,0.0,-0.07142857142857142,-0.005000000000000002,0.0,-0.09745068095405578,0.07517878322557159,0.0,0.0,-2.0,-0.14000000000000004,0.0,0,False,False,True,1764586782.5868554
3,112,-0.0037912645933158985,0.0026560361351240106,0.0,0.0,0.0,-0.005000000000000004,0.11638002365190532,-0.4246216344513806,0.2974760471338892,0.0,0.0,0.0,-0.5600000000000004,13.034562649013395,0,False,True,False,1764586795.0996068
