episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,32,-0.0029170442415177547,0.007888057562009547,0.0,0.0,-0.0625,-0.005000000000000002,0.0,-0.09334541572856815,0.2524178419843055,0.0,0.0,-2.0,-0.16000000000000006,0.0,0,False,False,True,1764586779.1426077
2,128,-0.005652876950047827,-0.0037991212694864973,0.0,0.0,-0.015625,-0.005000000000000004,0.0029942693373864516,-0.7235682496061219,-0.48628752249427165,0.0,0.0,-2.0,-0.6400000000000005,0.3832664751854658,0,False,False,True,1764586789.1944866
