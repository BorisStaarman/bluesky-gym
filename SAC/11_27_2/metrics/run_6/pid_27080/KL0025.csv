episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,87,-4.46033260606766e-05,0.03988035932521726,-1.3793103448275863,0.0,0.0,-0.005000000000000004,0.46687087230713104,-0.0038804893672788644,3.4695912612939015,-120.0,0.0,0.0,-0.4350000000000003,40.6177658907204,8,True,False,False,1764587784.7267148
