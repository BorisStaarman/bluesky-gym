episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,27,-0.006058212512717332,-0.004718543090400577,0.0,0.0,-0.07407407407407407,-0.005000000000000001,0.0,-0.16357173784336795,-0.12740066344081558,0.0,0.0,-2.0,-0.13500000000000004,0.0,0,False,False,True,1764586778.9026403
2,104,-0.0035584349049204702,0.003439893802453408,0.0,0.0,-0.019230769230769232,-0.005000000000000004,0.18338039919133886,-0.3700772301117289,0.3577489554551544,0.0,0.0,-2.0,-0.5200000000000004,19.07156151589924,0,False,False,True,1764586787.9997883
