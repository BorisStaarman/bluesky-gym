episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,11,-0.006078132579890026,-0.0020852200425054523,0.0,0.0,-0.18181818181818182,-0.004999999999999999,0.0,-0.06685945837879029,-0.022937420467559977,0.0,0.0,-2.0,-0.05499999999999999,0.0,0,False,False,True,1764586778.1163836
2,19,-0.0012212422854472574,0.014761524428381037,-0.7894736842105263,0.0,0.0,-0.005000000000000001,0.06503863053065728,-0.02320360342349789,0.2804689641392397,-15.0,0.0,0.0,-0.09500000000000001,1.2357339800824882,1,False,True,False,1764586782.1215959
3,125,-0.004416554652408379,0.0005451299583825735,0.0,0.0,-0.016,-0.005000000000000004,0.030010246353412103,-0.5520693315510473,0.06814124479782169,0.0,0.0,-2.0,-0.6250000000000004,3.751280794176513,0,False,False,True,1764586794.369649
