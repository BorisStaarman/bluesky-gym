episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,16,-0.002744318549691299,0.007321516040907361,-0.9375,0.0,0.0,-0.005,0.25532217724941236,-0.04390909679506078,0.11714425665451778,-15.0,0.0,0.0,-0.08,4.085154835990598,1,False,True,False,1764586778.3744223
2,61,-0.003889905690311253,0.0026379318873419816,-1.721311475409836,0.0,-0.03278688524590164,-0.005000000000000003,0.23879713992475568,-0.23728424710898643,0.1609138451278609,-105.0,0.0,-2.0,-0.30500000000000016,14.566625535410097,7,False,False,True,1764586786.0424788
3,126,-0.005106156814765772,-0.0031187928702313553,-0.8333333333333334,0.0,-0.015873015873015872,-0.005000000000000004,0.07275465305208913,-0.6433757586604872,-0.39296790164915074,-105.0,0.0,-2.0,-0.6300000000000004,9.16708628456323,7,False,False,True,1764586794.9603171
