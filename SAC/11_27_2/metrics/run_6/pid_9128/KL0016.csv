episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,23,-0.00456006836434684,0.00012232712846219678,0.0,0.0,0.0,-0.005000000000000002,0.4216113564891074,-0.10488157237997732,0.0028135239546305257,0.0,0.0,0.0,-0.11500000000000003,9.69706119924947,0,False,True,False,1764586778.7623887
2,117,-0.005200868599889491,-0.002286546629961332,0.0,0.0,-0.017094017094017096,-0.005000000000000004,0.02142781362554084,-0.6085016261870705,-0.2675259557054759,0.0,0.0,-2.0,-0.5850000000000004,2.507054194188278,0,False,False,True,1764586789.2830224
