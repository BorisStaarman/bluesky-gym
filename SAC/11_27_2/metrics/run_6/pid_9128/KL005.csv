episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,21,-0.0030029998219870853,0.006461108004322657,0.0,0.0,-0.09523809523809523,-0.005000000000000001,0.2884097348446102,-0.06306299626172879,0.1356832680907758,0.0,0.0,-2.0,-0.10500000000000002,6.056604431736814,0,False,False,True,1764586778.656794
2,37,-0.004968410159684764,-0.001228559507254108,0.0,0.0,-0.05405405405405406,-0.005000000000000002,0.0,-0.18383117590833628,-0.045456701768402,0.0,0.0,-2.0,-0.18500000000000008,0.0,0,False,False,True,1764586783.9737542
3,77,-0.0023135072526714456,0.01098479211832202,0.0,0.0,-0.025974025974025976,-0.005000000000000003,0.399912662371689,-0.17814005845570133,0.8458289931107956,0.0,0.0,-2.0,-0.38500000000000023,30.793275002620053,0,False,False,True,1764586793.3005996
