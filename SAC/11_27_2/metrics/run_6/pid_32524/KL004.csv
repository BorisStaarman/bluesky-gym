episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,47,-0.0032795358678690428,0.005631875614412859,0.0,0.0,-0.0425531914893617,-0.005000000000000003,0.04029766667985376,-0.154138185789845,0.26469815387740436,0.0,0.0,-2.0,-0.23500000000000013,1.8939903339531265,0,False,False,True,1764586779.847408
2,111,-0.004510600442298993,0.021266098586408835,0.0,0.0,0.0,-0.005000000000000004,0.04197970336586842,-0.5006766490951882,2.3605369430913807,0.0,0.0,0.0,-0.5550000000000004,4.659747073611395,0,True,False,False,1764586788.4881947
3,113,-0.005182030660594222,-0.002513380713286357,-2.3893805309734515,0.0,-0.017699115044247787,-0.005000000000000004,0.3112902218474095,-0.5855694646471471,-0.28401202060135833,-270.0,0.0,-2.0,-0.5650000000000004,35.175795068757274,18,False,False,True,1764586796.007057
