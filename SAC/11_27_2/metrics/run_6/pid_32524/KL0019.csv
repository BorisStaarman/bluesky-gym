episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,13,-0.0017201518177297438,0.009878503860028053,-1.1538461538461537,0.0,0.0,-0.004999999999999999,0.14207443743847287,-0.02236197363048667,0.1284205501803647,-15.0,0.0,0.0,-0.06499999999999999,1.8469676867001474,1,False,True,False,1764586778.1931007
2,143,-0.0047622879700545346,-0.001254467824534353,-2.5174825174825175,0.0,-0.013986013986013986,-0.005000000000000004,0.32073091765881534,-0.6810071797177984,-0.17938889890841248,-360.0,0.0,-2.0,-0.7150000000000005,45.864521225210595,24,False,False,True,1764586790.0540683
