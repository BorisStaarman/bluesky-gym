episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,91,-0.0052552565495874075,-0.0034395831307222798,-0.6593406593406593,0.0,-0.02197802197802198,-0.005000000000000004,0.19244384351473337,-0.47822834601245406,-0.31300206489572746,-60.0,0.0,-2.0,-0.4550000000000003,17.512389759840737,4,False,False,True,1764586781.403561
