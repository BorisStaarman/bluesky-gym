episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,51,-0.005849792707201532,-0.006412998421277272,0.0,0.0,-0.0392156862745098,-0.005000000000000002,0.0,-0.29833942806727815,-0.3270629194851409,0.0,0.0,-2.0,-0.2550000000000001,0.0,0,False,False,True,1764586779.9564013
2,138,-0.006251601896841852,-0.00778861216563495,0.0,0.0,-0.014492753623188406,-0.005000000000000004,0.003474141442367361,-0.8627210617641756,-1.074828478857623,0.0,0.0,-2.0,-0.6900000000000005,0.47943151904669584,0,False,False,True,1764586793.873294
