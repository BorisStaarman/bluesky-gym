episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,13,-0.0017357077371734657,0.009855050829797584,-1.1538461538461537,0.0,0.0,-0.004999999999999999,0.10344229020340225,-0.022564200583255055,0.12811566078736858,-15.0,0.0,0.0,-0.06499999999999999,1.3447497726442292,1,False,True,False,1764586778.2234035
2,35,-0.004518316531499462,-0.0013224613931919205,0.0,0.0,-0.05714285714285714,-0.005000000000000002,0.10831342608644157,-0.15814107860248117,-0.046286148761717216,0.0,0.0,-2.0,-0.17500000000000007,3.790969913025455,0,False,False,True,1764586786.3524795
3,109,-0.00714480402128765,-0.010982857474725917,0.0,0.0,-0.01834862385321101,-0.005000000000000004,0.03435334537705845,-0.7787836383203538,-1.197131464745125,0.0,0.0,-2.0,-0.5450000000000004,3.7445146460993706,0,False,False,True,1764586799.2815182
