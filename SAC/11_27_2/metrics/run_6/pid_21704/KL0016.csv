episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,17,-0.002343007499599636,0.009346106729644307,-8.823529411764707,0.0,0.0,-0.005,0.7059129454604516,-0.03983112749319381,0.15888381440395322,-150.0,0.0,0.0,-0.085,12.000520072827676,10,False,True,False,1764586778.4663615
2,125,-0.006205913783275063,-0.0074289518175236005,0.0,0.0,-0.016,-0.005000000000000004,0.0011672617331497952,-0.7757392229093829,-0.9286189771904501,0.0,0.0,-2.0,-0.6250000000000004,0.1459077166437244,0,False,False,True,1764586790.8874195
