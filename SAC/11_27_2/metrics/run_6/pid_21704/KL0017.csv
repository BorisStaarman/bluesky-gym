episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,61,-0.004103630761740733,0.0021174360810785383,-0.2459016393442623,0.0,0.0,-0.005000000000000003,0.29305861517404125,-0.2503214764661847,0.12916360094579082,-15.0,0.0,0.0,-0.30500000000000016,17.876575525616516,1,False,True,False,1764586780.2971807
2,8,-0.0007075735087829268,0.0122196522405352,0.0,0.0,0.0,-0.005,0.23968033270493638,-0.005660588070263414,0.0977572179242816,0.0,0.0,0.0,-0.04,1.917442661639491,0,False,True,False,1764586783.3761327
3,123,-0.005311721014634034,-0.0037660247371233283,0.0,0.0,-0.016260162601626018,-0.005000000000000004,0.015146137088857255,-0.6533416847999861,-0.46322104266616937,0.0,0.0,-2.0,-0.6150000000000004,1.8629748619294424,0,False,False,True,1764586797.114908
