episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,36,-0.00458017977759225,2.4568931703158573e-05,0.0,0.0,-0.05555555555555555,-0.005000000000000002,0.002658572266765618,-0.16488647199332102,0.0008844815413137086,0.0,0.0,-2.0,-0.18000000000000008,0.09570860160356225,0,False,False,True,1764586779.3929632
2,17,-0.005331689299266903,-0.0016397701448382799,-0.8823529411764706,0.0,0.0,-0.005,0.0873213254875342,-0.09063871808753735,-0.027876092462250757,-15.0,0.0,0.0,-0.085,1.4844625332880814,1,False,True,False,1764586781.7301655
3,163,-0.003266897585016914,0.0044536799470323634,0.0,0.0,-0.012269938650306749,-0.005000000000000004,0.0002641033543144927,-0.532504306357757,0.7259498313662752,0.0,0.0,-2.0,-0.8150000000000006,0.04304884675326231,0,False,False,True,1764586797.7553036
