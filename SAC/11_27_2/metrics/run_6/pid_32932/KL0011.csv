episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,9,-0.0010123792404004217,0.007459571543298497,0.0,0.0,0.0,-0.005,0.38246613512512145,-0.009111413163603796,0.06713614388968647,0.0,0.0,0.0,-0.045,3.442195216126093,0,False,True,False,1764586777.9611897
2,142,-0.004607853140124885,-0.0019723695429381544,-0.31690140845070425,0.0,-0.014084507042253521,-0.005000000000000004,0.10492675545749815,-0.6543151458977337,-0.2800764750972179,-45.0,0.0,-2.0,-0.7100000000000005,14.899599274964737,3,False,False,True,1764586789.480545
