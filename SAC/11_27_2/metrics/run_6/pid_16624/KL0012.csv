episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,8,-0.0008329746075643526,0.009556348026698303,-1.875,0.0,0.0,-0.005,0.19655182846073593,-0.0066637968605148205,0.07645078421358642,-15.0,0.0,0.0,-0.04,1.5724146276858875,1,False,True,False,1764586777.9355352
2,101,-0.004497148880640516,-0.000802667707763531,0.0,0.0,-0.019801980198019802,-0.005000000000000004,0.12488033588781364,-0.4542120369446921,-0.08106943848411663,0.0,0.0,-2.0,-0.5050000000000003,12.612913924669177,0,False,False,True,1764586786.1412015
