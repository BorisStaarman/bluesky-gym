episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,7,-0.0012916519048771248,0.008270358535628772,-2.142857142857143,0.0,0.0,-0.005,0.3500329337536754,-0.009041563334139874,0.05789250974940141,-15.0,0.0,0.0,-0.035,2.4502305362757277,1,False,True,False,1764586777.8643956
2,104,-0.0035864642287217756,0.005402964542517681,0.0,0.0,-0.019230769230769232,-0.005000000000000004,0.0755803674931416,-0.3729922797870647,0.5619083124218388,0.0,0.0,-2.0,-0.5200000000000004,7.860358219286727,0,False,False,True,1764586792.5538995
