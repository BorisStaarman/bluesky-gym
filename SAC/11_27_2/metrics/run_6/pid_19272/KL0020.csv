episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,14,-0.0018037827213400685,0.00721077820483107,-1.0714285714285714,0.0,0.0,-0.004999999999999999,0.10055675545125332,-0.02525295809876096,0.10095089486763498,-15.0,0.0,0.0,-0.06999999999999999,1.4077945763175466,1,False,True,False,1764586778.2912498
2,65,-0.0018412560075817866,0.012011131859972832,0.0,0.0,-0.03076923076923077,-0.005000000000000003,0.2331399414945132,-0.11968164049281613,0.7807235708982341,0.0,0.0,-2.0,-0.3250000000000002,15.154096197143359,0,False,False,True,1764586784.0968337
3,112,-0.005033694049917077,-0.0010474494625100877,0.0,0.0,-0.017857142857142856,-0.005000000000000004,0.11285834534575592,-0.5637737335907127,-0.11731433980112982,0.0,0.0,-2.0,-0.5600000000000004,12.640134678724664,0,False,False,True,1764586793.5767365
