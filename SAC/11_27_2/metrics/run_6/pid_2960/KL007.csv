episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,131,-0.003560329635980406,0.0029639066428964467,0.0,0.0,0.0,-0.005000000000000004,0.08683045531747044,-0.4664031823134332,0.3882717702194345,0.0,0.0,0.0,-0.6550000000000005,11.374789646588628,0,False,True,False,1764586783.3111477
2,13,-0.0014339940210717458,0.00968709250517938,-1.1538461538461537,0.0,0.0,-0.004999999999999999,0.15475739341046868,-0.018641922273932694,0.12593220256733195,-15.0,0.0,0.0,-0.06499999999999999,2.011846114336093,1,False,True,False,1764586789.1228423
3,88,-0.004144753055297188,0.0011168438806346574,0.0,0.0,-0.022727272727272728,-0.005000000000000004,0.03747794139154036,-0.3647382688661525,0.09828226149584984,0.0,0.0,-2.0,-0.4400000000000003,3.2980588424555517,0,False,False,True,1764586798.9190624
