episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,5,-0.0019767628943589055,0.009956187940195116,-3.0,0.0,0.0,-0.005,0.42463015561342,-0.009883814471794528,0.04978093970097558,-15.0,0.0,0.0,-0.025,2.1231507780671,1,False,True,False,1764586777.7795107
2,116,-0.005630741190429956,-0.0049761576158685265,-3.103448275862069,0.0,-0.017241379310344827,-0.005000000000000004,0.35410973943742347,-0.653165978089875,-0.5772342834407491,-360.0,0.0,-2.0,-0.5800000000000004,41.076729774741125,24,False,False,True,1764586794.4818656
