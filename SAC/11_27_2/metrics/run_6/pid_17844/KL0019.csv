episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,11,-0.00174287702704191,0.005832763444833088,-1.3636363636363635,0.0,0.0,-0.004999999999999999,0.2174551926095835,-0.01917164729746101,0.06416039789316397,-15.0,0.0,0.0,-0.05499999999999999,2.3920071187054184,1,False,True,False,1764586786.7052517
2,133,-0.0035504396201912593,0.004886899984291534,-1.4661654135338347,0.0,-0.015037593984962405,-0.005000000000000004,0.3975629196642659,-0.4722084694854375,0.649957697910774,-195.0,0.0,-2.0,-0.6650000000000005,52.87586831534736,13,False,False,True,1764586796.8305836
