episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,125,-0.0040015380876835495,0.0034680038882225935,0.0,0.0,-0.016,-0.005000000000000004,0.17453035259741473,-0.5001922609604437,0.4335004860278242,0.0,0.0,-2.0,-0.6250000000000004,21.81629407467684,0,False,False,True,1764586782.980503
