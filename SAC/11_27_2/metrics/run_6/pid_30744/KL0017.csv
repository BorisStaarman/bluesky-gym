episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,74,-0.003502219075659646,0.00605994075120844,-0.20270270270270271,0.0,0.0,-0.005000000000000003,0.03365262298268192,-0.2591642115988138,0.4484356155894246,-15.0,0.0,0.0,-0.3700000000000002,2.4902941007184625,1,False,True,False,1764586780.7194903
