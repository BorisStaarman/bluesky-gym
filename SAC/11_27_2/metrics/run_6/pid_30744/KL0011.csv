episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,74,-0.004519379147680116,-0.0004293279998510027,0.0,0.0,0.0,-0.005000000000000003,0.2135592033299683,-0.33443405692832856,-0.0317702719889742,0.0,0.0,0.0,-0.3700000000000002,15.803381046417655,0,False,True,False,1764586780.7194903
2,19,-0.000996949505917077,0.011041636891394731,-0.7894736842105263,0.0,0.0,-0.005000000000000001,0.0817655657316276,-0.018942040612424462,0.20979110093649989,-15.0,0.0,0.0,-0.09500000000000001,1.5535457489009246,1,False,True,False,1764586781.559589
3,110,-0.004523754609319599,0.0002570069452153202,-1.0909090909090908,0.0,0.0,-0.005000000000000004,0.13416254704424668,-0.4976130070251559,0.02827076397368522,-120.0,0.0,0.0,-0.5500000000000004,14.757880174867136,8,False,True,False,1764586796.1714332
