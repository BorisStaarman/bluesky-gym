episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,45,-0.004443143125381871,0.0021752030568133844,-0.3333333333333333,0.0,0.0,-0.005000000000000003,0.3147135180780417,-0.1999414406421842,0.0978841375566023,-15.0,0.0,0.0,-0.22500000000000012,14.162108313511878,1,False,True,False,1764586779.7502413
2,8,-0.0034850756631023107,0.0033877524871083198,0.0,0.0,-0.25,-0.005,0.0,-0.027880605304818486,0.027102019896866558,0.0,0.0,-2.0,-0.04,0.0,0,False,False,True,1764586781.0681536
3,110,-0.005416176618294095,-0.0037963673695285993,-0.13636363636363635,0.0,0.0,-0.005000000000000004,0.018944270267490043,-0.5957794280123504,-0.4176004106481459,-15.0,0.0,0.0,-0.5500000000000004,2.083869729423905,1,False,True,False,1764586796.1714332
