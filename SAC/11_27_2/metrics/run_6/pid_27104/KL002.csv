episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,155,-0.006326150127785856,-0.0064261287072691796,-1.064516129032258,0.0,-0.012903225806451613,-0.005000000000000004,0.10119359655560199,-0.9805532698068076,-0.9960499496267228,-165.0,0.0,-2.0,-0.7750000000000006,15.685007466118309,11,False,False,True,1764586784.9809675
2,125,-0.004840309540375191,-0.0007156748977003406,-1.2,0.0,-0.016,-0.005000000000000004,0.34700550225901855,-0.6050386925468989,-0.08945936221254258,-150.0,0.0,-2.0,-0.6250000000000004,43.37568778237732,10,False,False,True,1764586792.5508926
