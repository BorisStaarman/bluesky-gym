episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,27,-0.005940944676551855,-0.005747511725666388,0.0,0.0,-0.07407407407407407,-0.005000000000000001,0.0,-0.1604055062669001,-0.1551828165929925,0.0,0.0,-2.0,-0.13500000000000004,0.0,0,False,False,True,1764586778.922779
2,26,-0.0039536688732329205,0.000853128253278947,-0.5769230769230769,0.0,0.0,-0.005000000000000001,0.06388263281704584,-0.10279539070405594,0.02218133458525262,-15.0,0.0,0.0,-0.13000000000000003,1.6609484532431917,1,False,True,False,1764586786.4172587
3,90,-0.0037615895059971358,0.003972642423918894,0.0,0.0,-0.022222222222222223,-0.005000000000000004,0.29948773899715536,-0.33854305553974223,0.35753781815270047,0.0,0.0,-2.0,-0.4500000000000003,26.953896509743984,0,False,False,True,1764586797.0153542
