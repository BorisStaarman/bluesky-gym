episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,total_intrusions,terminated_waypoint,truncated,finished_at
1,299,-0.10004947773275483,-0.0020232189950978117,-0.5217391304347826,0.0,-0.010033444816053512,-0.05000000000000026,-29.914793842093694,-0.6049424795342457,-156.0,0.0,-3.0,-14.950000000000077,13,False,True,1764323130.9305825
