episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,total_intrusions,terminated_waypoint,truncated,finished_at
1,200,-0.10578482958083478,-0.007061309432830625,0.0,0.0,-0.015,-0.05000000000000004,-21.156965916166957,-1.412261886566125,0.0,0.0,-3.0,-10.000000000000007,0,False,True,1764323123.3590467
2,134,-0.08756832216267135,0.0038673348951171835,-0.5373134328358209,0.0,-0.022388059701492536,-0.049999999999999885,-11.734155169797962,0.5182228759457026,-72.0,0.0,-3.0,-6.699999999999984,6,False,True,1764323140.4750524
3,282,-0.09205910746505766,0.0002695738837806343,0.0,0.0,-0.010638297872340425,-0.05000000000000023,-25.96066830514626,0.07601983522613887,0.0,0.0,-3.0,-14.100000000000065,0,False,True,1764323179.3200083
