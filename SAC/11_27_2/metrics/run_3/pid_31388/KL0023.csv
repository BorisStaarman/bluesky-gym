episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,total_intrusions,terminated_waypoint,truncated,finished_at
1,78,-0.05663560437397372,0.018986667846892187,-3.5384615384615383,0.0,-0.038461538461538464,-0.049999999999999926,-4.41757714116995,1.4809600920575905,-276.0,0.0,-3.0,-3.899999999999994,23,False,True,1764323116.6267426
2,39,-0.07093723030462552,0.006909872316794965,-0.6153846153846154,0.0,-0.07692307692307693,-0.05000000000000003,-2.7665519818803954,0.26948502035500366,-24.0,0.0,-3.0,-1.950000000000001,2,False,True,1764323125.9414532
3,166,-0.06279553148418537,0.016096694518985703,0.0,0.0,-0.018072289156626505,-0.0499999999999999,-10.424058226374772,2.672051290151627,0.0,0.0,-3.0,-8.299999999999983,0,False,True,1764323158.3215244
