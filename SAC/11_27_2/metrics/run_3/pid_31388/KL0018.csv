episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,total_intrusions,terminated_waypoint,truncated,finished_at
1,69,-0.04001054550431985,0.10278445939845972,-2.782608695652174,0.0,0.0,-0.04999999999999994,-2.76072763979807,7.09212769849372,-192.0,0.0,0.0,-3.4499999999999957,16,True,False,1764323116.093053
2,255,-0.11172969630348424,-0.009567724587592906,0.0,0.0,-0.011764705882352941,-0.05000000000000018,-28.49107255738848,-2.4397697698361913,0.0,0.0,-3.0,-12.750000000000046,0,False,True,1764323141.7425504
