episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,total_intrusions,terminated_waypoint,truncated,finished_at
1,70,-0.08887606287265211,-0.0009313852741726731,-1.3714285714285714,0.0,-0.04285714285714286,-0.04999999999999993,-6.221324401085647,-0.06519696919208712,-96.0,0.0,-3.0,-3.4999999999999956,8,False,True,1764323116.1132915
2,300,-0.08735433334069617,0.001051895207415446,-0.68,0.0,0.0,-0.05000000000000026,-26.206300002208852,0.3155685622246338,-204.0,0.0,0.0,-15.000000000000078,17,False,True,1764323153.65552
