episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,total_intrusions,terminated_waypoint,truncated,finished_at
1,53,-0.0998915476663377,-0.0067896512574288775,-4.754716981132075,0.0,-0.05660377358490566,-0.049999999999999975,-5.294252026315898,-0.3598515166437305,-252.0,0.0,-3.0,-2.6499999999999986,21,False,True,1764323114.9691834
2,124,-0.06805618654854752,0.011910884877489359,-2.5161290322580645,0.0,-0.024193548387096774,-0.049999999999999885,-8.438967132019892,1.4769497248086805,-312.0,0.0,-3.0,-6.199999999999986,26,False,True,1764323138.1906755
3,207,-0.10005776843619912,-0.0029651489233928126,-0.057971014492753624,0.0,-0.014492753623188406,-0.05000000000000006,-20.711958066293217,-0.6137858271423122,-12.0,0.0,-3.0,-10.350000000000012,1,False,True,1764323178.656643
