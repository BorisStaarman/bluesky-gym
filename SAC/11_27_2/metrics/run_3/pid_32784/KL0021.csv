episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,total_intrusions,terminated_waypoint,truncated,finished_at
1,96,-0.11271454627699258,-0.012375411906766977,0.0,0.0,-0.03125,-0.049999999999999906,-10.820596442591288,-1.1880395430496298,0.0,0.0,-3.0,-4.799999999999991,0,False,True,1764323117.92061
2,140,-0.10155071149693998,-0.008221152013304303,-0.34285714285714286,0.0,-0.02142857142857143,-0.04999999999999988,-14.217099609571596,-1.1509612818626023,-48.0,0.0,-3.0,-6.999999999999983,4,False,True,1764323136.878813
3,220,-0.10306290606972458,-0.0050467099949192094,0.0,0.0,-0.013636363636363636,-0.0500000000000001,-22.67383933533941,-1.110276198882226,0.0,0.0,-3.0,-11.000000000000021,0,False,True,1764323168.9871645
