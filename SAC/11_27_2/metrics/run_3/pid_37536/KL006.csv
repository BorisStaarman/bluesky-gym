episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,total_intrusions,terminated_waypoint,truncated,finished_at
1,26,-0.09789401915181845,-0.00934118410687393,0.0,0.0,-0.11538461538461539,-0.05000000000000002,-2.5452444979472797,-0.2428707867787222,0.0,0.0,-3.0,-1.3000000000000005,0,False,True,1764323112.7823474
2,54,-0.02754821467815684,0.12917801652319885,0.0,0.0,0.0,-0.04999999999999997,-1.4876035926204694,6.975612892252737,0.0,0.0,0.0,-2.6999999999999984,0,True,False,1764323131.9582424
3,291,-0.08739147230154362,0.004462729495587415,0.0,0.0,-0.010309278350515464,-0.050000000000000246,-25.430918439749195,1.2986542832159378,0.0,0.0,-3.0,-14.550000000000072,0,False,True,1764323168.5742276
