episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,total_intrusions,terminated_waypoint,truncated,finished_at
1,175,-0.06794748152861492,0.04262302264985237,-0.6171428571428571,0.0,0.0,-0.04999999999999994,-11.890809267507612,7.4590289637241645,-108.0,0.0,0.0,-8.74999999999999,9,True,False,1764323121.6624482
2,146,-0.12849982915001876,-0.019449768196750275,-1.726027397260274,0.0,-0.02054794520547945,-0.04999999999999988,-18.76097505590274,-2.8396661567255403,-252.0,0.0,-3.0,-7.299999999999982,21,False,True,1764323133.5333335
3,266,-0.10044156067194115,-0.004726591466143554,-0.40601503759398494,0.0,-0.011278195488721804,-0.050000000000000204,-26.717455138736348,-1.2572733299941854,-108.0,0.0,-3.0,-13.300000000000054,9,False,True,1764323163.9869678
