episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,total_intrusions,terminated_waypoint,truncated,finished_at
1,48,-0.1225052233652195,-0.017591453442067344,-0.5,0.0,-0.0625,-0.04999999999999999,-5.880250721530536,-0.8443897652192326,-24.0,0.0,-3.0,-2.3999999999999995,2,False,True,1764323114.5475156
2,211,-0.08825374279927498,0.029416177063756186,0.0,0.0,0.0,-0.05000000000000007,-18.62153973064702,6.206813360452555,0.0,0.0,0.0,-10.550000000000015,0,True,False,1764323137.6886942
