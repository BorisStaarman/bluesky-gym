episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,total_intrusions,terminated_waypoint,truncated,finished_at
1,270,-0.09491250673267236,-0.0032919435175992784,0.0,0.0,-0.011111111111111112,-0.05000000000000021,-25.626376817821537,-0.8888247497518051,0.0,0.0,-3.0,-13.500000000000057,0,False,True,1764323128.694786
