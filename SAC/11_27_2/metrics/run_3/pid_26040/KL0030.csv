episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,total_intrusions,terminated_waypoint,truncated,finished_at
1,64,-0.08240317245434908,0.004241801157643082,-0.5625,0.0,-0.046875,-0.04999999999999995,-5.273803037078341,0.2714752740891572,-36.0,0.0,-3.0,-3.1999999999999966,3,False,True,1764323115.6466649
2,59,-0.13999976348968374,-0.027379991994920624,-0.6101694915254238,0.0,-0.05084745762711865,-0.04999999999999996,-8.25998604589134,-1.615419527700317,-36.0,0.0,-3.0,-2.9499999999999975,3,False,True,1764323126.8427532
3,293,-0.1009433389184904,-0.006219740148834234,-0.20477815699658702,0.0,-0.010238907849829351,-0.05000000000000025,-29.57639830311769,-1.8223838636084304,-60.0,0.0,-3.0,-14.650000000000073,5,False,True,1764323166.8536644
