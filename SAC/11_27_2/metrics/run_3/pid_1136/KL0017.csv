episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,total_intrusions,terminated_waypoint,truncated,finished_at
1,39,-0.11149121335891045,-0.011782605696373865,0.0,0.0,-0.07692307692307693,-0.05000000000000003,-4.348157320997507,-0.4595216221585807,0.0,0.0,-3.0,-1.950000000000001,0,False,True,1764323113.8267074
2,20,-0.09480460732033116,-0.005564169111698505,0.0,0.0,-0.15,-0.05000000000000001,-1.8960921464066232,-0.11128338223397011,0.0,0.0,-3.0,-1.0000000000000002,0,False,True,1764323131.6003282
3,230,-0.09649097317173728,-0.002617019138382825,-0.2608695652173913,0.0,-0.013043478260869565,-0.05000000000000012,-22.192923829499577,-0.6019144018280498,-60.0,0.0,-3.0,-11.500000000000028,5,False,True,1764323182.0989492
