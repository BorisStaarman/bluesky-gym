episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,total_intrusions,terminated_waypoint,truncated,finished_at
1,101,-0.11816523659351127,-0.01451186337068541,-0.4752475247524752,0.0,-0.0297029702970297,-0.0499999999999999,-11.934688895944639,-1.4656982004392263,-48.0,0.0,-3.0,-5.04999999999999,4,False,True,1764323118.2487206
2,63,-0.11149792722380227,-0.012005297536933615,0.0,0.0,-0.047619047619047616,-0.04999999999999995,-7.024369415099542,-0.7563337448268178,0.0,0.0,-3.0,-3.149999999999997,0,False,True,1764323127.404484
3,225,-0.10145088300299786,-0.005924769067879527,-0.10666666666666667,0.0,-0.013333333333333334,-0.050000000000000114,-22.826448675674516,-1.3330730402728936,-24.0,0.0,-3.0,-11.250000000000025,2,False,True,1764323156.8822122
