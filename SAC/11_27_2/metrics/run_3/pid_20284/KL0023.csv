episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,total_intrusions,terminated_waypoint,truncated,finished_at
1,89,-0.10799746166292032,-0.011121517218171178,0.0,0.0,-0.033707865168539325,-0.04999999999999991,-9.611774087999908,-0.9898150324172348,0.0,0.0,-3.0,-4.449999999999992,0,False,True,1764323117.5457442
2,300,-0.08331852812224037,0.00028690109213154105,-0.76,0.0,0.0,-0.05000000000000026,-24.995558436672113,0.08607032763946232,-228.0,0.0,0.0,-15.000000000000078,19,False,True,1764323154.52471
