episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,total_intrusions,terminated_waypoint,truncated,finished_at
1,123,-0.0451720471508841,0.02350562774819407,-0.6829268292682927,0.0,-0.024390243902439025,-0.049999999999999885,-5.556161799558744,2.8911922130278707,-84.0,0.0,-3.0,-6.149999999999986,7,False,True,1764323119.305162
2,50,-0.10240868805781593,-0.006492268627969489,0.0,0.0,-0.06,-0.04999999999999998,-5.120434402890797,-0.32461343139847443,0.0,0.0,-3.0,-2.499999999999999,0,False,True,1764323131.8131669
3,204,-0.11725380712405967,-0.015298328682940666,-0.4117647058823529,0.0,-0.014705882352941176,-0.05000000000000005,-23.919776653308173,-3.1208590513198957,-84.0,0.0,-3.0,-10.20000000000001,7,False,True,1764323169.7109978
