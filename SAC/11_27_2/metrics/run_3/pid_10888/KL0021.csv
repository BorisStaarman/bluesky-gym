episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,total_intrusions,terminated_waypoint,truncated,finished_at
1,56,-0.13703938279870484,-0.02516500140390503,0.0,0.0,-0.05357142857142857,-0.04999999999999997,-7.674205436727472,-1.4092400786186816,0.0,0.0,-3.0,-2.799999999999998,0,False,True,1764323115.1770387
2,248,-0.09070829968320114,2.233783488800121e-05,0.0,0.0,-0.012096774193548387,-0.05000000000000017,-22.495658321433883,0.005539783052224301,0.0,0.0,-3.0,-12.400000000000041,0,False,True,1764323145.8453887
