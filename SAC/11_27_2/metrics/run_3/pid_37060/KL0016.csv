episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,total_intrusions,terminated_waypoint,truncated,finished_at
1,157,-0.07596305164034697,0.010252099913408098,-0.07643312101910828,0.0,-0.01910828025477707,-0.04999999999999987,-11.926199107534474,1.6095796864050713,-12.0,0.0,-3.0,-7.84999999999998,1,False,True,1764323120.7967465
2,218,-0.06722046122912544,0.009649562718675639,-0.22018348623853212,0.0,-0.013761467889908258,-0.05000000000000009,-14.654060547949346,2.103604672671289,-48.0,0.0,-3.0,-10.90000000000002,4,False,True,1764323138.1154387
3,146,-0.1122553092643192,-0.013074649875817914,-0.9041095890410958,0.0,-0.02054794520547945,-0.04999999999999988,-16.389275152590603,-1.9088988818694155,-132.0,0.0,-3.0,-7.299999999999982,11,False,True,1764323177.583699
