episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,total_intrusions,terminated_waypoint,truncated,finished_at
1,151,-0.09685111305112912,-0.0027967593222285795,-0.8741721854304636,0.0,-0.019867549668874173,-0.04999999999999988,-14.624518070720496,-0.42231065765651554,-132.0,0.0,-3.0,-7.549999999999981,11,False,True,1764323120.5583112
2,110,-0.10672007573578335,-0.009240973756056455,0.0,0.0,-0.02727272727272727,-0.04999999999999989,-11.739208330936169,-1.01650711316621,0.0,0.0,-3.0,-5.4999999999999885,0,False,True,1764323130.4989033
3,229,-0.09032830877620437,0.0022844158491677844,-0.10480349344978165,0.0,-0.013100436681222707,-0.05000000000000012,-20.6851827097508,0.5231312294594226,-24.0,0.0,-3.0,-11.450000000000028,2,False,True,1764323160.1080647
