episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,total_intrusions,terminated_waypoint,truncated,finished_at
1,84,-0.12165674766410721,-0.01620879552877938,-2.142857142857143,0.0,-0.03571428571428571,-0.04999999999999992,-10.219166803785006,-1.3615388244174678,-180.0,0.0,-3.0,-4.199999999999993,15,False,True,1764323117.180953
2,218,-0.08230643301211556,0.0056218636111366885,-0.5504587155963303,0.0,-0.013761467889908258,-0.05000000000000009,-17.94280239664119,1.225566267227798,-120.0,0.0,-3.0,-10.90000000000002,10,False,True,1764323138.1154387
