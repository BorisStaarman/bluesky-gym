episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,total_intrusions,terminated_waypoint,truncated,finished_at
1,49,-0.11134962899757424,-0.007841005654008821,-1.9591836734693877,0.0,-0.061224489795918366,-0.04999999999999999,-5.456131820881137,-0.38420927704643226,-96.0,0.0,-3.0,-2.4499999999999993,8,False,True,1764323114.5921993
2,202,-0.08691354142706989,0.006523431176927485,-0.1782178217821782,0.0,-0.01485148514851485,-0.050000000000000044,-17.55653536826812,1.317733097739352,-36.0,0.0,-3.0,-10.100000000000009,3,False,True,1764323138.1399448
3,253,-0.11602361641121278,-0.007826899475340003,0.0,0.0,-0.011857707509881422,-0.050000000000000176,-29.353974952036832,-1.9802055672610208,0.0,0.0,-3.0,-12.650000000000045,0,False,True,1764323163.2893822
