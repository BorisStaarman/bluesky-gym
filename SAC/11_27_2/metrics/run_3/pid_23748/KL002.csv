episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,total_intrusions,terminated_waypoint,truncated,finished_at
1,201,-0.0705317808320048,0.012723045877852432,-0.1791044776119403,0.0,-0.014925373134328358,-0.05000000000000004,-14.176887947232965,2.557332221448339,-36.0,0.0,-3.0,-10.050000000000008,3,False,True,1764323123.3507767
