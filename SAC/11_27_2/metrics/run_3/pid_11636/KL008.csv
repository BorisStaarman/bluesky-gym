episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,total_intrusions,terminated_waypoint,truncated,finished_at
1,102,-0.13335874023524935,-0.020372157911979445,-1.0588235294117647,0.0,-0.029411764705882353,-0.0499999999999999,-13.602591503995434,-2.0779601070219034,-108.0,0.0,-3.0,-5.09999999999999,9,False,True,1764323118.2658722
2,62,-0.1054007720381744,-0.009732502429186753,0.0,0.0,-0.04838709677419355,-0.049999999999999954,-6.534847866366813,-0.6034151506095786,0.0,0.0,-3.0,-3.099999999999997,0,False,True,1764323126.4039197
3,252,-0.08567722865840925,0.0070022539033539125,-0.9047619047619048,0.0,-0.011904761904761904,-0.050000000000000176,-21.590661621919132,1.764567983645186,-228.0,0.0,-3.0,-12.600000000000044,19,False,True,1764323171.8633876
