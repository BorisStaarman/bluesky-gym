episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,total_intrusions,terminated_waypoint,truncated,finished_at
1,121,-0.10491174550699138,-0.006476279663674923,-0.39669421487603307,0.0,-0.024793388429752067,-0.04999999999999989,-12.694321206345958,-0.7836298393046657,-48.0,0.0,-3.0,-6.0499999999999865,4,False,True,1764323119.1893182
2,47,-0.09230723403136308,-0.006005538389944792,0.0,0.0,-0.06382978723404255,-0.049999999999999996,-4.338439999474065,-0.28226030432740523,0.0,0.0,-3.0,-2.3499999999999996,0,False,True,1764323127.018475
3,196,-0.06933560023318913,0.013412962590188916,-0.1836734693877551,0.0,-0.015306122448979591,-0.050000000000000024,-13.58977764570507,2.6289406676770275,-36.0,0.0,-3.0,-9.800000000000004,3,False,True,1764323157.991969
