episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,53,-0.0005663102263339731,0.05494956255986552,0.0,0.0,0.0,-0.005000000000000003,0.0,-0.030014441995700577,2.9123268156728725,0.0,0.0,0.0,-0.2650000000000001,0.0,0,True,False,False,1764661895.3902974
2,148,-0.0010765238372383438,0.0239123093860736,0.0,0.0,0.0,-0.005000000000000004,0.1850388767983346,-0.15932552791127488,3.539021789138893,0.0,0.0,0.0,-0.7400000000000005,27.385753766153524,0,True,False,False,1764661924.229723
