episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,79,-0.0007283179396961753,0.04164315043246002,0.0,0.0,0.0,-0.005000000000000003,0.022628141164761743,-0.057537117235997845,3.289808884164342,0.0,0.0,0.0,-0.39500000000000024,1.7876231520161778,0,True,False,False,1764677739.9427428
2,61,-0.00069521971671716,0.0460195342932012,0.0,0.0,0.0,-0.005000000000000003,0.052042151056886345,-0.04240840271974676,2.8071915918852732,0.0,0.0,0.0,-0.30500000000000016,3.174571214470067,0,True,False,False,1764677756.4534004
3,252,-0.0024207935767629495,0.01386343239990093,0.0,0.0,0.0,-0.004999999999999981,0.3614410379148761,-0.6100399813442633,3.4935849647750343,0.0,0.0,0.0,-1.2599999999999951,91.08314155454877,0,True,False,False,1764677795.0259311
