episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,164,-0.0017907834290283413,0.017178121082861153,0.0,0.0,0.0,-0.005000000000000004,0.4034598016112314,-0.293688482360648,2.8172118575892293,0.0,0.0,0.0,-0.8200000000000006,66.16740746424195,0,True,False,False,1764677749.0788937
2,155,-0.0018358619997492175,0.02221704576579098,0.0,0.0,0.0,-0.005000000000000004,0.20771713163687425,-0.2845586099611287,3.443642093697602,0.0,0.0,0.0,-0.7750000000000006,32.19615540371551,0,True,False,False,1764677766.9543786
