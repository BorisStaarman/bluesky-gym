episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,terminated_collision,truncated,finished_at
1,102,-0.0005865937895192829,0.0341162951250648,0.0,0.0,0.0,-0.005000000000000004,0.061157543124228934,-0.05983256653096686,3.4798621027566092,0.0,0.0,0.0,-0.5100000000000003,6.238069398671351,0,True,False,False,1764677742.42337
2,57,-0.0005534109564412079,0.05244741565404638,0.0,0.0,0.0,-0.005000000000000003,0.0,-0.031544424517148846,2.9895026922806434,0.0,0.0,0.0,-0.28500000000000014,0.0,0,True,False,False,1764677755.9826305
3,49,-0.000651092696206441,0.05771255407909242,0.0,0.0,0.0,-0.005000000000000003,0.04056121990396757,-0.031903542114115606,2.8279151498755284,0.0,0.0,0.0,-0.24500000000000013,1.987499775294411,0,True,False,False,1764677773.1524913
4,121,-0.0007658855603434756,0.028946775973831874,0.0,0.0,0.0,-0.005000000000000004,0.051165816961167954,-0.09267215280156055,3.5025598928336565,0.0,0.0,0.0,-0.6050000000000004,6.191063852301323,0,True,False,False,1764677808.991513
