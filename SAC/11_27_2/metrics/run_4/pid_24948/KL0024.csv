episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,71,-0.00046931622233782237,0.04610691527314856,-2.676056338028169,0.0,0.0,-0.02000000000000001,0.3866959323455866,-0.03332145178598539,3.2735909843935476,-190.0,0.0,0.0,-1.4200000000000008,27.455411196536648,19,True,False,1764576906.1752965
2,50,-0.0023110793467098455,0.013282080777579908,-1.8,0.0,-0.02,-0.020000000000000007,0.22251074828532347,-0.11555396733549228,0.6641040388789954,-90.0,0.0,-1.0,-1.0000000000000004,11.125537414266173,9,False,True,1764576917.077208
