episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,94,-0.002078705429040534,0.01355940933927685,-0.6382978723404256,0.0,-0.010638297872340425,-0.020000000000000014,0.7563130157506311,-0.19539831032981023,1.274584477892024,-60.0,0.0,-1.0,-1.8800000000000012,71.09342348055932,6,False,True,1764576908.7360926
2,17,-0.00241986846296403,0.01165303323899144,0.0,0.0,-0.058823529411764705,-0.02,0.0,-0.041137763870388505,0.19810156506285448,0.0,0.0,-1.0,-0.34,0.0,0,False,True,1764576912.7985945
