episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,56,-0.0009644931579471174,0.05099654784516195,-1.25,0.0,0.0,-0.02000000000000001,0.16422470731590844,-0.05401161684503857,2.8558066793290693,-70.0,0.0,0.0,-1.1200000000000006,9.196583609690872,7,True,False,1764576904.3838975
2,27,-0.00015943383829250245,0.09212834166789936,0.0,0.0,0.0,-0.020000000000000004,0.00010811379067472331,-0.004304713633897566,2.487465225033283,0.0,0.0,0.0,-0.5400000000000001,0.0029190723482175295,0,True,False,1764576914.13151
