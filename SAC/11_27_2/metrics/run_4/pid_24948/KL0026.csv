episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,49,-0.0011017156002070252,0.0573399857162278,-2.2448979591836733,0.0,0.0,-0.02000000000000001,0.3576369145637169,-0.053984064410144236,2.8096593000951624,-110.0,0.0,0.0,-0.9800000000000005,17.524208813622128,11,True,False,1764576903.5250366
2,48,-0.0030216449421273527,0.009936657127794757,-2.2916666666666665,0.0,-0.020833333333333332,-0.02000000000000001,0.3436603737128206,-0.14503895722211294,0.4769595421341484,-110.0,0.0,-1.0,-0.9600000000000005,16.49569793821539,11,False,True,1764576916.8358412
