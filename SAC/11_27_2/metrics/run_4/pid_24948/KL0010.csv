episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,32,-0.002020659778305972,0.07638823216996074,-3.4375,0.0,0.0,-0.020000000000000007,0.4193877785103607,-0.0646611129057911,2.4444234294387437,-110.0,0.0,0.0,-0.6400000000000002,13.420408912331542,11,True,True,1764576901.3431737
2,59,-0.0019446777246817561,0.01464298512167181,-0.1694915254237288,0.0,-0.01694915254237288,-0.02000000000000001,0.12037178683193285,-0.11473598575622361,0.8639361221786368,-10.0,0.0,-1.0,-1.1800000000000006,7.101935423084038,1,False,True,1764576918.1414971
