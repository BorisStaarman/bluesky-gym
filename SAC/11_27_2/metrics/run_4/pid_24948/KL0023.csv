episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,84,-0.001340499756024113,0.016111889103829068,0.0,0.0,-0.011904761904761904,-0.02000000000000001,0.10263907791352432,-0.1126019795060255,1.3533986847216417,0.0,0.0,-1.0,-1.680000000000001,8.621682544736043,0,False,True,1764576907.6507683
2,47,-0.002316292776862664,0.013409542206267373,-1.4893617021276595,0.0,-0.02127659574468085,-0.02000000000000001,0.19992224545233755,-0.10886576051254519,0.6302484836945665,-70.0,0.0,-1.0,-0.9400000000000005,9.396345536259865,7,False,True,1764576916.7082317
