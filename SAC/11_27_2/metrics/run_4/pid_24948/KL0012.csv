episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,109,-0.0024104140203367206,0.013225213209968473,-0.3669724770642202,0.0,-0.009174311926605505,-0.020000000000000014,0.0776654954194453,-0.26273512821670253,1.4415482398865636,-40.0,0.0,-1.0,-2.1800000000000015,8.465539000719538,4,False,True,1764576910.3626263
2,30,-0.002385427221811725,0.07936945906841072,0.0,0.0,0.0,-0.020000000000000007,0.0,-0.07156281665435175,2.381083772052322,0.0,0.0,0.0,-0.6000000000000002,0.0,0,True,False,1764576914.528169
