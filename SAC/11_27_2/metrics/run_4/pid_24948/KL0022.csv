episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,91,-0.002257008458735198,0.013056623381822773,-0.43956043956043955,0.0,-0.01098901098901099,-0.020000000000000014,0.30662793713941455,-0.205387769744903,1.1881527277458723,-40.0,0.0,-1.0,-1.8200000000000012,27.903142279686726,4,False,True,1764576908.4139993
2,45,-0.0021396488852522635,0.058101585088651,-1.3333333333333333,0.0,0.0,-0.02000000000000001,0.22797195941765683,-0.09628419983635185,2.614571328989295,-60.0,0.0,0.0,-0.9000000000000005,10.258738173794557,6,True,False,1764576916.4541626
