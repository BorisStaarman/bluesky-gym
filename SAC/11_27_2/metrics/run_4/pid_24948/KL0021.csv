episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,19,-0.00016948825397223625,0.1227307187142313,0.0,0.0,0.0,-0.020000000000000004,0.0,-0.0032202768254724888,2.331883655570395,0.0,0.0,0.0,-0.38000000000000006,0.0,0,True,False,1764576899.6348295
2,94,-0.002787520606288824,0.0112534417999161,-1.9148936170212767,0.0,-0.010638297872340425,-0.020000000000000014,0.2892614200366151,-0.2620269369911495,1.0578235291921134,-180.0,0.0,-1.0,-1.8800000000000012,27.19057348344182,18,False,True,1764576922.0584416
