episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,86,-0.002004228862305037,0.014147776316657354,-0.6976744186046512,0.0,-0.011627906976744186,-0.020000000000000014,0.1633456945352703,-0.1723636821582332,1.2167087632325324,-60.0,0.0,-1.0,-1.720000000000001,14.047729730033247,6,False,True,1764576907.8731532
2,24,-0.0022953614672055226,0.01245925757445667,0.0,0.0,-0.041666666666666664,-0.020000000000000007,0.0,-0.05508867521293254,0.29902218178696005,0.0,0.0,-1.0,-0.48000000000000015,0.0,0,False,True,1764576913.7384942
