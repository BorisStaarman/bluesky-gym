episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,62,-0.0014328973541382468,0.046952757211330756,-1.1290322580645162,0.0,0.0,-0.02000000000000001,0.2673147906592235,-0.0888396359565713,2.9110709471025067,-70.0,0.0,0.0,-1.2400000000000007,16.573517020871854,7,True,False,1764576905.111846
2,72,-0.0007714599998261463,0.04404082441922748,-0.8333333333333334,0.0,0.0,-0.02000000000000001,0.12087726989085328,-0.05554511998748254,3.1709393581843783,-60.0,0.0,0.0,-1.4400000000000008,8.703163432141436,6,True,False,1764576919.6237535
