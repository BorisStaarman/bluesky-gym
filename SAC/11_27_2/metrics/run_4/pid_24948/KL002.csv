episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,49,-0.002639878687581835,0.05269393567196389,0.0,0.0,0.0,-0.02000000000000001,0.013837784778251224,-0.1293540556915099,2.5820028479262307,0.0,0.0,0.0,-0.9800000000000005,0.67805145413431,0,True,True,1764576903.5250366
2,53,-0.002093811884359777,0.014071018858967445,-1.1320754716981132,0.0,-0.018867924528301886,-0.02000000000000001,0.2966501907624144,-0.11097202987106818,0.7457639995252746,-60.0,0.0,-1.0,-1.0600000000000005,15.722460110407962,6,False,True,1764576917.4398115
