episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,50,-0.00031426714581570355,0.05829506932727369,0.0,0.0,0.0,-0.020000000000000007,0.03634891220525856,-0.015713357290785178,2.9147534663636847,0.0,0.0,0.0,-1.0000000000000004,1.817445610262928,0,True,False,1764576903.6508994
2,62,-0.00297511544231624,0.009803558936031834,-1.2903225806451613,0.0,-0.016129032258064516,-0.02000000000000001,0.22733734425803034,-0.18445715742360688,0.6078206540339737,-80.0,0.0,-1.0,-1.2400000000000007,14.094915343997881,8,False,True,1764576918.489806
