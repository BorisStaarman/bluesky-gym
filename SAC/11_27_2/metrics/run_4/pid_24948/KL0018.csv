episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,48,-0.0025853035793573505,0.01235369317023164,0.0,0.0,-0.020833333333333332,-0.02000000000000001,0.00948855755853334,-0.12409457180915281,0.5929772721711187,0.0,0.0,-1.0,-0.9600000000000005,0.4554507628096003,0,False,True,1764576903.398335
2,61,-0.002038263010226055,0.01412734471835551,-0.9836065573770492,0.0,-0.01639344262295082,-0.02000000000000001,0.1092136500085203,-0.12433404362378936,0.8617680278196861,-60.0,0.0,-1.0,-1.2200000000000006,6.6620326505197385,6,False,True,1764576918.3729246
