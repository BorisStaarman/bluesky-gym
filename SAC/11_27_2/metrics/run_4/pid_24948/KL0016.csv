episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,61,-0.002227162379576335,0.013923705844048414,-2.459016393442623,0.0,-0.01639344262295082,-0.02000000000000001,0.3180941931910205,-0.13585690515415644,0.8493460564869533,-150.0,0.0,-1.0,-1.2200000000000006,19.40374578465225,15,False,True,1764576904.9919221
2,89,-0.0020833525538860712,0.01410521755232953,-0.2247191011235955,0.0,-0.011235955056179775,-0.020000000000000014,0.088270797935107,-0.18541837729586036,1.2553643621573283,-20.0,0.0,-1.0,-1.7800000000000011,7.856101016224523,2,False,True,1764576921.5122995
