episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,80,-0.0023264423737916515,0.013236208425597107,0.0,0.0,-0.0125,-0.02000000000000001,0.052961142365298995,-0.18611538990333212,1.0588966740477685,0.0,0.0,-1.0,-1.600000000000001,4.23689138922392,0,False,True,1764576907.2050245
2,108,-0.002660064524066871,0.011758520754578086,-0.46296296296296297,0.0,-0.009259259259259259,-0.020000000000000014,0.16048277682526743,-0.28728696859922204,1.2699202414944333,-50.0,0.0,-1.0,-2.1600000000000015,17.332139897128883,5,False,True,1764576923.5885317
