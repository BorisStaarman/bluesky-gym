episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,68,-0.002266793298302633,0.013546237190059117,-1.0294117647058822,0.0,-0.014705882352941176,-0.02000000000000001,0.14845264519146636,-0.15414194428457906,0.92114412892402,-70.0,0.0,-1.0,-1.3600000000000008,10.094779873019712,7,False,True,1764576905.8230972
2,30,-0.0020880031317900304,0.014162412491805276,-0.6666666666666666,0.0,-0.03333333333333333,-0.020000000000000007,0.23157805841326523,-0.06264009395370092,0.4248723747541583,-20.0,0.0,-1.0,-0.6000000000000002,6.947341752397957,2,False,True,1764576914.528169
