episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,70,-0.0022733810258211817,0.013650553746115615,-0.7142857142857143,0.0,-0.014285714285714285,-0.02000000000000001,0.13356083763486018,-0.15913667180748273,0.9555387622280931,-50.0,0.0,-1.0,-1.4000000000000008,9.349258634440213,5,False,True,1764576906.0586216
2,92,-0.0016990536192293512,0.014933209481408978,0.0,0.0,-0.010869565217391304,-0.020000000000000014,0.09282391258377555,-0.15631293296910032,1.373855272289626,0.0,0.0,-1.0,-1.8400000000000012,8.53979995770735,0,False,True,1764576921.8424919
