episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,69,-0.002209236764628363,0.013704517608944186,-0.2898550724637681,0.0,-0.014492753623188406,-0.02000000000000001,0.1327230827822733,-0.15243733675935706,0.9456117150171488,-20.0,0.0,-1.0,-1.3800000000000008,9.157892711976857,2,False,True,1764576905.942275
2,76,-0.0009372603389655246,0.04201435278545661,-0.9210526315789473,0.0,0.0,-0.02000000000000001,0.1732184115814455,-0.07123178576137987,3.1930908116947023,-70.0,0.0,0.0,-1.520000000000001,13.164599280189858,7,True,False,1764576920.0700114
