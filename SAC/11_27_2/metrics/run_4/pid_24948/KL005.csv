episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,80,-0.0019152279125271194,0.03882080367596218,-0.75,0.0,0.0,-0.02000000000000001,0.16809072817570836,-0.15321823300216955,3.1056642940769748,-60.0,0.0,0.0,-1.600000000000001,13.447258254056669,6,True,False,1764576907.2050245
2,12,-0.0002990111918130289,0.18295979709514465,0.0,0.0,0.0,-0.019999999999999997,0.00024325602901812746,-0.0035881343017563467,2.195517565141736,0.0,0.0,0.0,-0.23999999999999996,0.0029190723482175295,0,True,False,1764576912.1202216
