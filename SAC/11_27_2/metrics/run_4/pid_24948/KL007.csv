episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,89,-0.0020920204607475395,0.0350027499310718,-4.044943820224719,0.0,0.0,-0.020000000000000014,0.8833092886858124,-0.186189821006531,3.1152447438653903,-360.0,0.0,0.0,-1.7800000000000011,78.6145266930373,36,True,False,1764576908.1979468
2,51,-0.001339421704630471,0.016098659577707255,-1.3725490196078431,0.0,-0.0196078431372549,-0.020000000000000007,0.3278624258725974,-0.06831050693615402,0.8210316384630699,-70.0,0.0,-1.0,-1.0200000000000005,16.720983719502467,7,False,True,1764576917.2003884
