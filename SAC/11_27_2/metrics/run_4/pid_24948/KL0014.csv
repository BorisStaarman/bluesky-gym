episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,46,-0.00222800354780728,0.013301368679424237,-0.21739130434782608,0.0,-0.021739130434782608,-0.02000000000000001,0.06908460159963378,-0.10248816319913488,0.6118629592535149,-10.0,0.0,-1.0,-0.9200000000000005,3.177891673583154,1,False,True,1764576903.1457467
2,52,-0.0026963676023058184,0.010612667328378848,0.0,0.0,-0.019230769230769232,-0.02000000000000001,0.007090440769472618,-0.14021111531990255,0.5518587010757001,0.0,0.0,-1.0,-1.0400000000000005,0.36870292001257615,0,False,True,1764576917.3226395
