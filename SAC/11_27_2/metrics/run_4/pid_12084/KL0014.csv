episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,46,-0.0014990452846583928,0.015586339855311129,-1.3043478260869565,0.0,-0.021739130434782608,-0.02000000000000001,0.18804306227257161,-0.06895608309428607,0.7169716333443119,-60.0,0.0,-1.0,-0.9200000000000005,8.649980864538295,6,False,True,1764576766.2838178
2,86,-0.0023976206475013768,0.0125106354382963,-1.3953488372093024,0.0,-0.011627906976744186,-0.020000000000000014,0.26669354336148937,-0.2061953756851184,1.0759146476934818,-120.0,0.0,-1.0,-1.720000000000001,22.935644729088086,12,False,True,1764576787.552341
