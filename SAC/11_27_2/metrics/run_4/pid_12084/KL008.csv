episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,73,-0.0006248894657942753,0.04506005341533951,-0.136986301369863,0.0,0.0,-0.02000000000000001,0.06988622444492813,-0.0456169310029821,3.2893838993197844,-10.0,0.0,0.0,-1.4600000000000009,5.101694384479754,1,True,False,1764576769.6046746
2,152,-0.003078699158764715,0.0092766671936844,-1.25,0.0,-0.006578947368421052,-0.020000000000000014,0.23460960996435695,-0.46796227213223673,1.4100534134400289,-190.0,0.0,-1.0,-3.0400000000000023,35.66066071458226,19,False,True,1764576794.748893
