episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,131,-0.0024549324570510085,0.026668315181376693,-2.9770992366412212,0.0,0.0,-0.020000000000000014,0.4275140314880559,-0.3215961518736821,3.493549288760347,-390.0,0.0,0.0,-2.620000000000002,56.00433812493532,39,True,False,1764576776.1172833
2,26,-0.00012828101644384143,0.09492394360714641,0.0,0.0,0.0,-0.020000000000000004,0.0,-0.0033353064275398773,2.4680225337858066,0.0,0.0,0.0,-0.5200000000000001,0.0,0,True,False,1764576780.1715305
