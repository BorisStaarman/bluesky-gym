episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,67,-0.0022028894649619053,0.013826325915181348,-1.9402985074626866,0.0,-0.014925373134328358,-0.02000000000000001,0.25606093819268244,-0.14759359415244766,0.9263638363171504,-130.0,0.0,-1.0,-1.3400000000000007,17.156082858909723,13,False,True,1764576768.8965998
2,44,-9.095514282086219e-05,0.06404419774567918,0.0,0.0,0.0,-0.02000000000000001,0.06360612736963177,-0.004002026284117936,2.817944700809884,0.0,0.0,0.0,-0.8800000000000004,2.7986696042637975,0,True,False,1764576782.4834182
