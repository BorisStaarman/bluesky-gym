episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,57,-0.0023446538008459507,0.013099598389549683,-1.9298245614035088,0.0,-0.017543859649122806,-0.02000000000000001,0.318336169380927,-0.13364526664821919,0.746677108204332,-110.0,0.0,-1.0,-1.1400000000000006,18.14516165471284,11,False,True,1764576767.6797302
2,55,-0.0016348553683386573,0.015318058048250314,0.0,0.0,-0.01818181818181818,-0.02000000000000001,0.006892114392439273,-0.08991704525862615,0.8424931926537673,0.0,0.0,-1.0,-1.1000000000000005,0.37906629158416005,0,False,True,1764576783.8588703
