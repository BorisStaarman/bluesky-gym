episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,59,-0.0023600895067867407,0.013197620889060804,-1.0169491525423728,0.0,-0.01694915254237288,-0.02000000000000001,0.12743638401961171,-0.1392452809004177,0.7786596324545875,-60.0,0.0,-1.0,-1.1800000000000006,7.518746657157091,6,False,True,1764576767.9294384
2,21,-0.002538625058806388,0.012278415719955475,0.0,0.0,-0.047619047619047616,-0.020000000000000004,0.0,-0.05331112623493414,0.25784673011906495,0.0,0.0,-1.0,-0.4200000000000001,0.0,0,False,True,1764576779.512262
