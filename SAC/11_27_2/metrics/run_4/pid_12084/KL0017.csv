episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,101,-0.0016720197539464637,0.032936374524914894,-3.4653465346534653,0.0,0.0,-0.020000000000000014,0.4167301640523828,-0.16887399514859283,3.3265738270164045,-350.0,0.0,0.0,-2.0200000000000014,42.08974656929066,35,True,False,1764576772.8251522
2,89,-0.0024287159600228075,0.013174094038291345,0.0,0.0,-0.011235955056179775,-0.020000000000000014,0.18656919045772358,-0.21615572044202988,1.1724943694079297,0.0,0.0,-1.0,-1.7800000000000011,16.604657950737398,0,False,True,1764576787.893581
