episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,80,-0.002418943366463444,0.012960460176669806,-0.75,0.0,-0.0125,-0.02000000000000001,0.11178448129275201,-0.19351546931707553,1.0368368141335844,-60.0,0.0,-1.0,-1.600000000000001,8.94275850342016,6,False,True,1764576770.4235978
2,114,-0.002149594462776762,0.01315242210640361,-0.5263157894736842,0.0,-0.008771929824561403,-0.020000000000000014,0.12473989087869908,-0.24505376875655088,1.4993761201300115,-60.0,0.0,-1.0,-2.2800000000000016,14.220347560171694,6,False,True,1764576790.635566
