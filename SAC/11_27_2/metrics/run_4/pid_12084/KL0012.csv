episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,49,-0.0014705389163332154,0.05644459085001584,0.0,0.0,0.0,-0.02000000000000001,0.10849338518545883,-0.07205640690032755,2.765784951650776,0.0,0.0,0.0,-0.9800000000000005,5.316175874087483,0,True,True,1764576766.6722763
2,27,-0.0003127885800433143,0.09194983194243703,0.0,0.0,0.0,-0.020000000000000004,0.02487751119437469,-0.008445291661169486,2.4826454624457996,0.0,0.0,0.0,-0.5400000000000001,0.6716928022481167,0,True,False,1764576780.300395
