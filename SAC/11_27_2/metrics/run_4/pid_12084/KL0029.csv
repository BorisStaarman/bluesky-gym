episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,84,-0.0010180589925824126,0.03963897430260167,-2.380952380952381,0.0,0.0,-0.02000000000000001,0.32015612074210675,-0.08551695537692265,3.3296738414185407,-200.0,0.0,0.0,-1.680000000000001,26.89311414233697,20,True,False,1764576770.8989923
2,26,-0.002305609972425093,0.08950771636473517,0.0,0.0,0.0,-0.020000000000000004,0.008156311036104683,-0.05994585928305241,2.3272006254831146,0.0,0.0,0.0,-0.5200000000000001,0.21206408693872175,0,True,False,1764576780.1715305
