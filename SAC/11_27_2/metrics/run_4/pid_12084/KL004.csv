episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,26,-0.00012862799269238592,0.09492387598780597,0.0,0.0,0.0,-0.020000000000000004,0.0,-0.003344327810002034,2.4680207756829553,0.0,0.0,0.0,-0.5200000000000001,0.0,0,True,False,1764576763.6818728
2,36,-0.0004190225784153635,0.07368334327192769,-2.2222222222222223,0.0,0.0,-0.020000000000000007,0.24959221311088925,-0.015084812822953087,2.652600357789397,-80.0,0.0,0.0,-0.7200000000000003,8.985319671992013,8,True,False,1764576781.4633446
