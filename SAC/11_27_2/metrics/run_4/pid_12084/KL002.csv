episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,60,-0.0028106959891795722,0.01100618032899256,-1.8333333333333333,0.0,-0.016666666666666666,-0.02000000000000001,0.29369047794322106,-0.16864175935077433,0.6603708197395536,-110.0,0.0,-1.0,-1.2000000000000006,17.621428676593265,11,False,True,1764576768.0520716
2,54,-0.0018691667656595306,0.05153894477552575,0.0,0.0,0.0,-0.02000000000000001,0.18108478031088548,-0.10093500534561466,2.7831030178783904,0.0,0.0,0.0,-1.0800000000000005,9.778578136787816,0,True,False,1764576783.7355337
