episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,52,-0.002519954070583909,0.012686851511484649,0.0,0.0,-0.019230769230769232,-0.02000000000000001,0.0011613509978891374,-0.13103761167036326,0.6597162785972017,0.0,0.0,-1.0,-1.0400000000000005,0.06039025189023514,0,False,True,1764576767.0573013
2,89,-0.0024317135518171656,0.012461836055889297,-0.7865168539325843,0.0,-0.011235955056179775,-0.020000000000000014,0.3716258940540124,-0.21642250611172772,1.1091034089741474,-70.0,0.0,-1.0,-1.7800000000000011,33.07470457080711,7,False,True,1764576787.893581
