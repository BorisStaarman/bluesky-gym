episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,84,-0.0024163512452141387,0.01314652422282882,0.0,0.0,-0.011904761904761904,-0.02000000000000001,0.04792627822907904,-0.20297350459798766,1.1043080347176208,0.0,0.0,-1.0,-1.680000000000001,4.02580737124264,0,False,True,1764576770.8989923
2,92,-0.0022291734731004318,0.013845429027908881,0.0,0.0,-0.010869565217391304,-0.020000000000000014,0.14148759130608768,-0.20508395952523972,1.273779470567617,0.0,0.0,-1.0,-1.8400000000000012,13.016858400160066,0,False,True,1764576788.2348335
