episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,89,-0.0024386904013149087,0.012357443367832531,0.0,0.0,-0.011235955056179775,-0.020000000000000014,0.13697851685426213,-0.21704344571702686,1.0998124597370953,0.0,0.0,-1.0,-1.7800000000000011,12.19108800002933,0,False,True,1764576771.4732723
2,58,-0.0016653995297139794,0.04813901495383767,-1.896551724137931,0.0,0.0,-0.02000000000000001,0.4403661136475473,-0.09659317272341081,2.792062867322585,-110.0,0.0,0.0,-1.1600000000000006,25.541234591557743,11,True,False,1764576784.223617
