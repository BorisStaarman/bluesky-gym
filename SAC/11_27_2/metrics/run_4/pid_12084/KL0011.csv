episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,111,-0.003237639362732012,0.008760832514804737,-2.8828828828828827,0.0,-0.009009009009009009,-0.020000000000000014,0.3953395624501542,-0.3593779692632533,0.9724524091433258,-320.0,0.0,-1.0,-2.2200000000000015,43.88269143196712,32,False,True,1764576773.9306636
2,43,-0.0019594272147461125,0.06075144300357944,-0.6976744186046512,0.0,0.0,-0.02000000000000001,0.09627966734662811,-0.08425537023408283,2.612312049153916,-30.0,0.0,0.0,-0.8600000000000004,4.140025695905009,3,True,False,1764576782.3591013
