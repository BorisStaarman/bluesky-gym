episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,124,-0.0030088382818523893,0.00914028432000966,-2.096774193548387,0.0,-0.008064516129032258,-0.020000000000000014,0.48661320843708783,-0.3730959469496963,1.1333952556811977,-260.0,0.0,-1.0,-2.4800000000000018,60.34003784619889,26,False,True,1764576775.360109
2,94,-0.002712597960993943,0.032273777234550736,0.0,0.0,0.0,-0.020000000000000014,0.1836594257022062,-0.25498420833343066,3.0337350600477695,0.0,0.0,0.0,-1.8800000000000012,17.263986016007383,0,True,False,1764576788.4580142
