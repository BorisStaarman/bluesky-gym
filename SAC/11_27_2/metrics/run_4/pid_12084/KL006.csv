episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,41,-0.0026040648971646214,0.06095194600141026,0.0,0.0,0.0,-0.02000000000000001,0.0,-0.10676666078374947,2.499029786057821,0.0,0.0,0.0,-0.8200000000000004,0.0,0,True,False,1764576765.634803
2,80,-0.0014892644145808166,0.039809083564088105,-1.375,0.0,0.0,-0.02000000000000001,0.38452996682822266,-0.11914115316646533,3.1847266851270484,-110.0,0.0,0.0,-1.600000000000001,30.762397346257814,11,True,False,1764576786.8611162
