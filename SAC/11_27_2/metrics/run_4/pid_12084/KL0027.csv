episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,52,-0.0007431244874194532,0.05582420060366598,0.0,0.0,0.0,-0.02000000000000001,0.17630820314514983,-0.038642473345811564,2.902858431390631,0.0,0.0,0.0,-1.0400000000000005,9.16802656354779,0,True,False,1764576767.0573013
2,21,-0.0022598304891691618,0.10741439482194154,0.0,0.0,0.0,-0.020000000000000004,0.0006474885551576023,-0.0474564402725524,2.2557022912607723,0.0,0.0,0.0,-0.4200000000000001,0.013597259658309649,0,True,False,1764576779.512262
