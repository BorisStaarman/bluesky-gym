episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,123,-0.0030217224988046765,0.009595501912052905,-1.2195121951219512,0.0,-0.008130081300813009,-0.020000000000000014,0.4826466666578769,-0.3716718673529752,1.1802467351825072,-150.0,0.0,-1.0,-2.4600000000000017,59.36553999891886,15,False,True,1764576775.2503812
2,75,-0.0032949197768038065,0.0077565203507386875,-3.2,0.0,-0.013333333333333334,-0.02000000000000001,0.37018065775291426,-0.2471189832602855,0.5817390263054015,-240.0,0.0,-1.0,-1.5000000000000009,27.763549331468568,24,False,True,1764576786.2677133
