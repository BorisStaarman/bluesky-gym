episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,25,-0.00021246793968188443,0.09778761618660775,-1.2,0.0,0.0,-0.020000000000000004,0.18772161319022715,-0.005311698492047111,2.444690404665194,-30.0,0.0,0.0,-0.5000000000000001,4.693040329755679,3,True,False,1764576763.5480874
2,84,-0.0022140797932358627,0.01356080426660099,0.0,0.0,-0.011904761904761904,-0.02000000000000001,0.07498120512056462,-0.18598270263181246,1.1391075583944832,0.0,0.0,-1.0,-1.680000000000001,6.2984212301274285,0,False,True,1764576787.3229513
