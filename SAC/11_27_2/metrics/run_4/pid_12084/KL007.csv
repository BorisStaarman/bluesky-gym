episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,135,-0.00275626954024644,0.010025761045877716,-1.9259259259259258,0.0,-0.007407407407407408,-0.020000000000000014,0.48671297746564895,-0.3720963879332694,1.3534777411934917,-260.0,0.0,-1.0,-2.700000000000002,65.7062519578626,26,False,True,1764576776.5434005
2,26,-0.001912881634719297,0.013896642831077418,0.0,0.0,-0.038461538461538464,-0.020000000000000004,0.0,-0.04973492250270172,0.36131271360801287,0.0,0.0,-1.0,-0.5200000000000001,0.0,0,False,True,1764576780.1715305
