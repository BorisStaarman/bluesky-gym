episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,29,-0.002278173581742382,0.08183591789355188,-2.413793103448276,0.0,0.0,-0.020000000000000007,0.33026202805704236,-0.06606703387052908,2.3732416189130046,-70.0,0.0,0.0,-0.5800000000000002,9.577598813654228,7,True,False,1764576764.075025
2,18,-0.0025092186945439225,0.012430892581521524,0.0,0.0,-0.05555555555555555,-0.020000000000000004,0.09209743290058706,-0.045165936501790606,0.22375606646738744,0.0,0.0,-1.0,-0.36000000000000004,1.657753792210567,0,False,True,1764576779.1094313
