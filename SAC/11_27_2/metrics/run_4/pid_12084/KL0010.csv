episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,41,-0.0025331472233210673,0.05945496815100759,-1.7073170731707317,0.0,0.0,-0.02000000000000001,0.30207662311266725,-0.10385903615616375,2.437653694191311,-70.0,0.0,0.0,-0.8200000000000004,12.385141547619357,7,True,False,1764576765.634803
2,56,-0.001240910247579039,0.05233051400693438,-1.9642857142857142,0.0,0.0,-0.02000000000000001,0.3430752316664139,-0.0694909738644262,2.930508784388325,-110.0,0.0,0.0,-1.1200000000000006,19.21221297331918,11,True,False,1764576783.9815056
