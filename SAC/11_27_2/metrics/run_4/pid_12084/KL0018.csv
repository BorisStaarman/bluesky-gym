episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,63,-0.0003617702458249765,0.04998449520359996,0.0,0.0,0.0,-0.02000000000000001,5.500033159758952e-05,-0.02279152548697352,3.1490231978267973,0.0,0.0,0.0,-1.2600000000000007,0.0034650208906481395,0,True,False,1764576768.4185529
2,64,-0.0018787150277688024,0.0150938397168926,-1.5625,0.0,-0.015625,-0.02000000000000001,0.467827194196891,-0.12023776177720336,0.9660057418811264,-100.0,0.0,-1.0,-1.2800000000000007,29.940940428601024,10,False,True,1764576784.9494004
