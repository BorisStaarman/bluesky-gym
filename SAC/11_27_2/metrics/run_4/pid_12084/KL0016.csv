episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,88,-0.0019986241000972006,0.014348989995654905,-0.22727272727272727,0.0,-0.011363636363636364,-0.020000000000000014,0.04710177487409688,-0.17587892080855363,1.2627111196176317,-20.0,0.0,-1.0,-1.7600000000000011,4.144956188920525,2,False,True,1764576771.3618417
2,80,-0.0014637880222607951,0.040894909507887725,-2.875,0.0,0.0,-0.02000000000000001,0.6634347861811903,-0.11710304178086361,3.271592760631018,-230.0,0.0,0.0,-1.600000000000001,53.07478289449523,23,True,False,1764576786.8611162
