episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,21,-0.002183327368779633,0.10845993152341189,-1.9047619047619047,0.0,0.0,-0.020000000000000004,0.4034911599985289,-0.045849874744372285,2.27765856199165,-40.0,0.0,0.0,-0.4200000000000001,8.473314359969107,4,True,False,1764576763.0155687
2,106,-0.0021226752259846326,0.01382355368363532,-0.9433962264150944,0.0,-0.009433962264150943,-0.020000000000000014,0.208602908609148,-0.22500357395437107,1.465296690465344,-100.0,0.0,-1.0,-2.1200000000000014,22.11190831256969,10,False,True,1764576789.7648675
