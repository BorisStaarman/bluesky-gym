episode_index,steps,mean_reward_drift,mean_reward_progress,mean_reward_intrusion,mean_reward_path_efficiency,mean_reward_boundary,mean_reward_step,mean_reward_proximity,sum_reward_drift,sum_reward_progress,sum_reward_intrusion,sum_reward_path_efficiency,sum_reward_boundary,sum_reward_step,sum_reward_proximity,total_intrusions,terminated_waypoint,truncated,finished_at
1,87,-0.0003357484542895214,0.041390869548957585,0.0,0.0,0.0,-0.020000000000000014,0.1304678522396589,-0.02921011552318836,3.60100565075931,0.0,0.0,0.0,-1.740000000000001,11.350703144850325,0,True,False,1764576771.2477562
2,45,-0.0012393994003622724,0.016279377844418495,0.0,0.0,-0.022222222222222223,-0.02000000000000001,0.29439054349181565,-0.05577297301630226,0.7325720029988323,0.0,0.0,-1.0,-0.9000000000000005,13.247574457131703,0,False,True,1764576782.6094234
